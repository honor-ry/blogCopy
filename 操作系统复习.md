---
title: 操作系统学习笔记
date: 2019-11-04 10:44:14
tags: 操作系统
mathjax: true
---



2019年11月份，操作系统复习笔记！<!--more-->

Linux、Windows、Android的界面属于外壳（Shell），而不是内核(Kernel)，Kernel是我们研究的重点，在Shell之下。

Kernel-操作系统内部组件，包括：

- CPU调度 
- 物理内存管理
- 虚拟内存管理
- 文件系统管理
- 中断处理与设备驱动

OS Kernel的特征：

- 并发：一个时间段内，多个程序同时运行（并行，在同一个时间点上，有多个程序同时运行，需要多核）
- 共享：“同时”访问，互斥共享
- 虚拟：将硬件虚拟化，比如CPU虚拟化为进程、磁盘虚拟化为文件系统、内存虚拟化为地址空间。利用多道程序设计技术，让每个用户都觉得有一个计算机专门为他服务。
- 异步：程序的执行不是一贯到底，而是走走停停，向前推进的速度不可预知。但只要运行环境相同，OS需要保证程序运行的结果也要相同。

操作系统结构：

- 微内核的设计，尽可能把内核功能移动用户空间
  - 只在操作系统内核放最基本的功能，比如中断处理、消息传递
  - 而其他功能比如文件系统、网络协议栈都是放在外围，以进程(服务)的形式存在，进制之间通过内核的消息机制进行通讯。
- 外核：主要在学术界有研究
  - 分为两层：一层主要面向硬件，来复制硬件的功能；另一层主要面向应用，针对不同的应用有不同的Library Operating system
  - 这样可以提高并发的效率，并且可以针对不同的应用设计Lib OS可以提高应用的运行效率
- VMM(虚拟机监视器)：操作系统之下是VMM，VMM之下是硬件，VMM之上是多个虚拟计算机。

## 操作系统启动

操作系统一开始存放在：DISK

BIOS: 基本I/O处理系统，功能让计算机系统检测各种外设

Bootloader：加载OS，放在硬盘的第一个主引导扇区，一个扇区512个字节

- BIOS开始从一个固定地址开始执行，完成POST(加电自检)、寻找显卡和执行BIOS，从硬盘中加载Bootloader。并将控制权将给Bootloader。

- 然后Bootloader从硬盘找到操作系统的起始扇区以及操作系统的长度，将磁盘中的这个区域加载到内存中，即加载OS，并将控制权交给OS。
- 从OS起始地址开始执行，完成一些操作。

## 中断、异常和系统调用

操作系统与设备和程序交互

面向外设：中断和IO

面向应用程序：异常和系统调用

### 定义

**系统调用**：应用程序主动向操作系统发出服务请求，System call

**异常**：非法指令或其他坏的处理状态（如：内存出错） exception

**中断**：来自不同的硬件设备的计时器和网络的中断 interupt

为什么不让应用程序直接访问硬件？

- 在计算机运行中，内核是被信任的第三方

- 只有内核可以执行特权指令

- 为了方便应用程序，屏蔽底层的差异性

三者区别：

- 源头：
  - 中断：外设
  - 异常：应用程序意想不到的行为，让操作系统应对意外事件的支持；比如应用程序执行除0操作，此时计算机系统无法正常工作
  - 系统调用：应用程序请求操作提供服务
- 处理时间
  - 中断：异步，不知道什么时候产生
  - 异常：同步，执行某条指令时产生
  - 系统调用：异步或同步，执行某条指令时产生，也可能是异步的，即发出请求，响应的时间是不确定的(异步)

- 响应
  - 中断：持续，对用户应用程序透明的
  - 异常：杀死或者重新执行意想不到的应用程序指令
  - 系统调用：等待和持续

### 中断

硬件：设置中断表示

- 将内部、外部事件设置中断标记
- 中断事件的ID

软件：

- 保存当前处理状态
- 中断服务程序处理
- 清楚中断标记
- 恢复之前保存的处理状态

### 异常

异常编号

- 保存现场
- 异常处理
  - 杀死产生了异常的程序
  - 重新执行异常指令：操作系统服务不到位，比如内存不足，但是操作系统收到异常后，回收了足够的内存，就可以重新执行异常指令
- 恢复现场

### 系统调用

程序访问主要通过高层次的API接口，而不是直接进行系统调用。

- Win32 API用于Windows。
- POSIX API用于POSIX-Based systems，包括UNIX、LINUX、Max OS 
- Java API 用于JAVA虚拟机(JVM)

应用程序处于用户态，操作系统处于内核态。只有在内核态才能访问外设、执行特权指令。所以如果应用程序需要访问外设都需要通过操作系统进行处理，即通过系统调用，将系统调用的参数传递到内核态。

注意，应用程序中函数的调用一般只需要一个栈，而系统调用需要两个栈，即用户栈和内核栈，所以在系统调用时，需要进行栈的切换。

跨越操作系统边界的开销：

- 在执行时间上的开销超过程序调用
- 开销：
  - 建立中断/异常/系统调用号与对应服务例程映射关系的初始化开销
  - 建立内核堆栈
  - 验证参数
  - 内核态映射到用户态的地址空间，更新页面映射权限
  - 内核态独立地址空间，TLB

# 内存

## 计算机体系结构及内存分层体系

### 计算机体系结构/内存分层体系

计算机体系结构：

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191008101917.png)

内存层次结构：

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191008101947.png)

CPU访问的指令所处的位置。

CPU可以访问CPU寄存器和cache，这两者都位于CPU内部，速度快，容量小，存放的指令优先。

主存主要用于存放操作系统本身和运行的代码。CPU速度相当快，在主存中可以存放多个程序，在主存中放不下的数据，可以存放到磁盘中。而且主存一停电数据就没了，需要永久保存的数据放到磁盘中。磁盘速度比主存慢很多，但容量大。

操作系统在内存管理上要完成的任务：

- 抽象
  - 逻辑地址空间 ！= 物理地址空间
- 保护(隔离)
  - 同时运行多个不同的应用程序，每个应用有一片独立的地址空间
- 共享
  - 进程间可以使用共享内存进行交互和数据的传递
- 虚拟
  - 内存不足时可以使用硬盘获得更多的地址空间

### 地址空间和地址生成

物理地址空间：硬件支持的地址看嘛

逻辑地址空间：一个运行的程序所拥有的内存范围

两者之间怎么对应关系的？

#### 逻辑地址生成

```c++
A[C程序.c] --> |编译| B[编译程序.s]
B --> |汇编| C[汇编程序.o]
C --> |链接| D[执行程序.exe]
D --> |加载| E[应有载入内存]
```

各个步骤的作用：

- 编译：C程序代码中，每个指针（变量名、函数名）就代表一个逻辑地址，但该地址对硬件而言不友好的，因此先经过编译，将代码转为语法树，通过符号来描述地址。
- 汇编：经过汇编，将上一步的语法树转为机器语言，使用一段相对连续的，从零开始的地址描述程序。更加接近底层硬件语言。
- 链接：一个大的程序，可能通过.o文件组成，所以通过链接，将多个从零开始描述的.o文件组合到一起，并且使之不发生内存冲突。由此组成成为一个.exe应用程序，但此时该程序还存放到硬盘上。
- 载入(程序重定位)：将上一步中，硬盘上的应用程序，通过一定的偏移量加载到内存中。此时的地址依然是逻辑地址。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191008122549.png)

逻辑地址到物理地址的过程：

- CPU中MMU(内存管理单元)根据逻辑地址请求指令的内容。

- CPU中的MMU查询逻辑地址中的映射表是否存在对应的物理地址，注意MMU有一块区域存储映射表。
- 如果找到了对应的物理地址，CPU的控制器向主存发起请求对应物理地址的内容。如果没有找到，则会去内存中查找。
- 主存通过总线将指令的内容传给CPU，CPU执行指令。

操作系统需要建立逻辑地址到物理地址的映射关系，存放在内存中，由CPU进行缓存，从而加快访问过程。

操作系统确保内存中的程序相互不干扰：

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191010154343.png)

起始地址和长度，指出一段区域是程序可以访问的。超出这个范围就是不合法的。

如果CPU执行某条指令，根据映射关系，判断逻辑地址是否在可以访问的区域，如果满足就根据映射关系找到对应的物理地址，读取物理地址的数据。如果不满足，就会产生内存异常。这就是地址的安全检测

### 连续内存分配

内存的碎片问题：

空闲内存不能被利用

- 外部碎片：在分配单元间的无法使用的内存
- 内部碎片：在分配单元中的未使用的内存

简单的内存管理方法：

- 当一个程序准许运行在内存时，分配一个连续的空间
- 分配一个连续的内存空间给运行的程序以访问数据

#### 分配策略

##### 首次适配

如要分配N byte，在内存中查找第一个可用（>=N）的空闲块，以满足最快分配。

为了分配n字节，使用第一次可用空闲块以致块的尺寸比n大。

需求：空闲块按照地址排序；分配需要寻找一个合适的分区

优势：实现简单； 适合大量分配小内存。
劣势：重分配慢； 易产生大量微小的外部碎片。

##### 最佳适配

如要分配N byte，在内存中查找第一个可用（>=N）的且最小的空闲块，以满足最快分配。更大的利用小空间。

需求：1. 按照剩余空间大小排序； 2. 分配需要寻找 最 合适的空闲块； 3. 内存回收后，要将相邻块进行合并。
优势：实现简单； 适合大量分配小内存。
劣势：重分配慢； 易产生大量微小的外部碎片。

##### 最差适配

如要分配N byte，在内存中查找第一个可用（>=N）的且最大的空闲块，以满足最快分配。避免出现大量微小空间。

需求：1. 按照剩余空间大小排序（倒序排列）； 2. 分配需要寻找 最 合适的空闲块； 3. 内存回收后，要将相邻块进行合并。
优势：适合大量分配中等大小内存。
劣势：重分配慢； 易产生外部碎片； 会破坏大的空闲块，使更大的应用无法分配。

### 压缩式碎片整理

将非运行时应用占用的内存移动到相邻的一处内存，以减少应用间的外部碎片

### 交换式碎片整理

利用虚拟内存(磁盘)，将非运行时应用占用的内存移动到虚拟内存，以使的运行时应用有更大的空闲空间使用。

## 非连续内存分配

连续分配内存的缺点：

- 分配给一个车程序的物理内存是连续的
- 内存利用率较低
- 有外碎片、内碎片的问题

非连续分配的优点：

- 一个程序的物理地址空间是非连续的
- 更好的内存利用和管理
- 允许共享代码与数据
- 支持动态加载和动态链接

非连续分配缺点：

- 如何建立虚拟地址和物理地址之间的转换
  - 软件方案
  - 硬件方案
- 两种硬件方案
  - 分段
  - 分页

### 分段

#### 程序的分段地址空间

数据分段：栈段、堆段、共享段

分段：更好的分离和共享

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191010201257.png)

左侧是连续的逻辑地址，右侧是不连续的物理地址。中间需要一个映射来建立关系。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191010201451.png)

#### 分段寻址方案

段访问机制

一个段：一个内存“块”

程序访问内存地址需要一个2维的二元组(s,addr):

- s：段号
- addr：段内偏移

实现寻址的有两种方案：段寄存器+地址寄存器，x86采用该方案；另一种单段地址实现方案

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191010201908.png)

段的硬件实现：

- 首先，CPU执行程序P中的指令，这时候需要寻址，采用单地址实现方案，把一个逻辑地址分为两部分：段号和偏移。
- 根据段号找到段所在物理内存的起始地址，这时候需要段表来存放逻辑地址段号到物理地址的映射关系。
- CPU比对偏移是否小于等于段的长度限制，如果大于，这抛出内存异常；否则将基地址加上偏移得到真实的物理地址。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191010202010.png)

段表包括两个信息：

- 段的起始地址
- 段的长度限制

段号决定了索引段表中的哪一项。段表由操作系统建立。

根据段号就可以确定逻辑地址在物理内存中的起始地址。

### 分页

#### 分页地址空间

划分物理内存到固定大小的帧(frame)，大小是2的幂，例如512，4096，8192。

划分逻辑地址空间至相同大小的页，大小是2的幂，例如512，4096，8192。

建立方案转换逻辑地址为物理地址（pages to frames）:

- 页表
- MMU/TLB

**页帧：**物理内存被分割为大小相等的帧

一个内存物理地址是一个二元组(f,o):

- f : 页帧号（F位，共有2^F个帧）
- o: 帧内偏移（S位，每帧有2^S字节），所以一帧的大小位2^S

物理地址：2^S×f+o，（其中2^S×f是基地址，o是偏移）

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191010204858.png)

地址计算实例：

16bit的地址空间，9bit（512byte）大小的页帧。

物理地址：(3,6)，对应的实际物理地址位：2^9×3+6=512×3+6=1542

这里F=7，S=9，f=3，o=6

**页：**一个程序的逻辑地址空间被划分位大小相等的页：

- 页内偏移大小=帧内偏移大小
- 页号大小<>帧号大小

一个逻辑地址是一个二元组(p,o):

- p页号（P位，2^P个页）
- o页内偏移（S位，每页有2^S字节）

虚拟地址：2^S×p+o

#### 页寻址方案

程序运行时，CPU去寻址，地址是一个逻辑地址，分为两部分：页号p和页内偏移o

根据页号查找页表，以页号为索引，可以得到帧号。在这个过程中，根据页表基址和页号来得到帧号。

根据帧号，结合页内偏移，得到了帧号和帧偏移，从而可以计算得到物理地址。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191010210941.png)

页表由操作系统建立。

一般而言，逻辑地址空间大于物理地址空间，这个时候需要采用虚拟内存，后续会介绍。

逻辑地址空间是连续的，映射到物理地址空间，就不一定连续了，这有助于减少碎片。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191010211248.png)

页机制有利于减少内存碎片。

### 页表

每个运行的程序都有一个页表：

- 属于程序运行状态，会动态变化
- PTBR：页表基址寄存器

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191010211640.png)

页表项中的前三个bit有别的用途：

- 页的读写情况
- 逻辑地址空间有没有对应到物理地址空间

地址转换实例：

首先CPU读取逻辑地址，根据页号和页表基地址找到对应的页表项，比如页号是4，则对应页表中第二项，即Flags位为100，第二位为0，表示不存在该对应关系，即对应的逻辑地址没有对应的物理地址，抛出内存异常。

再来看(3,1023)，页号为3，即页表中第一项，即Flags为011，第二位为1，表示存在对应的映射关系。即可以得到该页号对应的帧号（00100=4），根据帧号加上帧偏移(等于页偏移1023)得到实际的物理地址，即(4,1023)，然后根据帧号到物理地址的关系计算得到实际物理地址。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191010212716.png)

#### 分页机制的问题

- 访问一个内存单元需要2次内存访问
  - 一次获取页表项
  - 一次用于访问数据
- 页表可能非常大
  - 64位机器如果每页1024字节，那么一个页表的大小会是多大？ 2^64/2^10=2^54，一般计算机内存无法存储一个页表。
  - 计算机系统中可以跑多个应用程序，每个运行的程序都有一个自己的页表。

如何处理？

- 缓存（Caching）
- 间接访问（Indirection）

#### Translation Look-aside Bufer(TLB)

- 缓存近期访问的页帧转换表项
  - TLB使用关联内存实现，具备快速访问性能
  - 如果TLB命中，物理页号可以快速被获取
  - 如果TLB未命中，对应的页表项被更新到TLB中

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191015100429.png)

TLB的容量有限，把经常访问的页表项映射关系存储到TLB。TLB缺失不会很大，一个页4K，访问4K次才会引起一次TLB缺失。

对于TLB未命中时，将页表项更新到TLB的实现方式有两种：一种是硬件实现，另一种是操作系统实现。x86采用的硬件实现。

#### 二级页表

将page number分成两部分：p1,p2，即第一级页表的页号和第二级页表的页号。根据p1查找第一级页表项得到第二级页表的起始地址，然后根据p2和第二级页表的起始地址得到一个二级页表项，即一个起始地址，起始地址加上偏移o得到物理地址。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191015101108.png)

#### 多级页表

通过把页号分为k位，来实现多级间接页表。

建立页表“树”。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191015101641.png)

多级页表通过时间换取空间，时间的开销可以通过TLB来缓解。

#### 反向页表

大地址空间问题：

- 有大地址空间（64-bits），前向映射页表变得繁琐
- 不是让页表与逻辑地址空间的大小相对应，而是让页表与物理地址空间的大小相应对

##### 基于页寄存器的方案

将物理地址的帧号作为页表的索引，然后第二项中存储逻辑地址的页号。这样页表的存储开销比较少，只跟物理地址空间有关，而与逻辑地址无关。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191015102417.png)

每个帧和一个寄存器关联，寄存器内容包括：

- 此帧是否被占用
- 对应的页号
- 保护位

页寄存器的一个例子：

物理内存大小：4096×4096=4K×4K=16MB

页表大小：4096bytes = 4KB

页帧数：4097= 4K

页寄存器使用的空间：8 × 4096 = 32KB

页寄存器带来的额外开销：32K/32M = 0.2%

虚拟内容的大小：任意

现在的问题是，如何根据逻辑地址的页号来查找帧号？

##### 基于关联内存的方案

类似TLB，将页号设置为Value，将帧号设置为Key。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191015103304.png)

开销太大，设计成本太大，硬件逻辑太复杂。还需要放入CPU中。

##### 基于哈希查找的方案

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191015103839.png)

为了提高效率，hash计算加入一个参数，即PID，当前进程ID。

根据PID和页号p通过hash计算得到帧号。

存在的问题：

- hash碰撞
- 还是需要将反向页表存储到内存中，存储开销大，还是需要TLB来缓解

## 虚拟内存

### 虚拟内存起因

程序在运行时，进程发现内存不够用。程序的规模的增长速度远远大于存储容量的增长速度。让更多的程序跑在有限的内存中。

理想的存储器：更大、更快、更便宜的非易失性存储器

容量很少，速度更快的，放在CPU更近的地方，即寄存器。

Cache，缓存内存中的数据，尽量保证CPU访问数据更快。

由于内存远远无法满足，所以考虑是否用上磁盘。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191015142733.png)

不常用的数据放到磁盘上去，虚拟出大内存：

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191015143410.png)

对于内存不够用的情况，怎么办？

- 如果是程序太大，超过了内存的容量，可以采用**手动的覆盖（overlay）技术**，只把需要的指令和数据保存在内存当中；
- 如果是程序太多，超过了内存的容量，可以采用**自动的交换（swapping）技术**，把暂时不能执行的程序送到外存中；
- 如果想要在有限容量的内存中，以更小的页粒度为单位转入更多更大的程序，可以采用**自动的虚拟存储技术**。

### 覆盖技术

上世纪八九十年代。

目标：是在较小的可用内存中运行较大的程序。常用于多道程序系统，与分区存储管理配合使用。

原理：

- 把个程序按照其自身逻辑结构，划分为若干个功能上相对独立的程序模块，那些不会同时执行的模块共享同一块内存区域，按时间先后来运行。
  - 必要部分（常用）的代码和数据常驻内存；
  - 可选部分（不常用功能）在其他程序模块中实现，平时存放在外存中，在需要使用到时才转入内存；
  - 不存在调用关系的模块不必同时转入到内存，从而可以相互覆盖，即这些模块共用一个分区。

下面就是一个例子：

内存总共就110K，但是程序大小为190K，内存无法加载整个程序，所以考虑使用覆盖技术。A首先调用B，然后将B导出到磁盘中，然后再调用C。C在调用E时，D和F不会存放在内存中。

![1571123841590](C:\Users\zxp\AppData\Roaming\Typora\typora-user-images\1571123841590.png)

另一种覆盖方案（100K）：

- A占用一个分区20K
- B、C、F占用一个分区50K
- D、E占用一个分区30K

覆盖技术 缺点：

- 由程序员来把一个大的程序划分为若干个小的功能模块，并确定各个模块之前的覆盖关系，费时费力，增加了编程的复杂度；
- 覆盖模块从外存转入内存，实际上是以时间延长来换取空间节省。

### 交换技术

目标：多道程序在内存中时，让正在运行的程序或需要运行的程序获得更多的内存资源。

方法：

- 可将暂时不能运行的程序送到外存，从而获得空闲内存空间。
- 操作系统把一个进程的整个地址空间的内容保存到外存中（换出swap out），而将外存中的某个进程的地址空间读入内存中（换入swap in）。换入换出内容的大小为整个程序的地址空间。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191015153912.png)

交换技术实现中的几个问题：

- 交换时机的确定：何时需要交换？只当内存空间不够或有不够的危险时换出；
- 交换区的大小：必须足够大以存放所有用户进程的所有内存映像拷贝；必须能对这些内存映像进行直接存取；
- 程序换入时的重定位：换出后再换入的内存位置一定要在原来的位置

覆盖和交换的比较：

- 覆盖只能发生在那些相互之间没有调用关系的程序模块之间，因此程序员必须给出程序内的各个模块之间的逻辑覆盖结构。
- 交换技术是以在内存中的程序大小为单位来进行的，它不需要程序员给出各个模块之间的逻辑覆盖结构。换言之，交换发生在内存中程序与管理程序或操作系统之间，而覆盖则发生在运行程序的内部。

### 虚存技术

在内存不足的情形下，可以采用覆盖技术和交换技术，但是两者存在缺点：

对于覆盖技术，需要程序员自己把整个程序划分位若干个小的功能模块，并确定各个模块之间的覆盖关系，增加了程序员的负担；

对于交换技术，以进程作为交换的单位，需要把进程的整个地址空间都换进换出，增加了处理器的开销。

四海之内的解决之道：虚拟内存管理技术——虚存技术。

**目标：**

- 像覆盖技术那样，不是把程序的所有内容都放到内存中，因而能够运行比当前的空闲内存空间还要大的程序。但做得更好，由操作系统自动来加成，无须程序员干涉；
- 像交换技术那样，能够实现进程在内存与外存之间的交换，因而获得更多的空闲内存空间。但做得更好，只对进程的部分内容在内存和外存之间进行交换。

**程序的局部性原理**：指程序在执行过程中的一个较短时间内，所执行的指令地址和指令的操作数地址，分别局限于一定区域。这可以表现为：

- 时间局部性：一条指令的一次执行和下次执行，一个数据的一次访问和下次访问都集中在一个较短时期内；
- 空间局部性：当前指令和邻近的几条指令，当前访问的数据和邻近的几个数据集中在一个较小区域内。

程序的局部性原理表明，从理论上来说，虚拟存储技术是能够实现的，而且在实现了以后应该是能够取得一个满意的效果的。

程序的局部性好，程序执行效率高，得到高效的虚存管理。

**程序的编写方法对缺页率的影响：**

程序1是按照列来访问数组；程序2是按照行来访问数组的。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191016134903.png)

在c语言中，数组是按照行来存储的。$a_{0,0}, ...a_{0,1023}$占用一个页，而且是连续存储的。

对于程序1，首先产生中断从磁盘中读取第一行数据，访问$a_{0,0}$，正常访问，然后访问$a_{1,0}$位置上跟$a_{1,0}$相差一个页，不具备空间局部性和时间局部性，需要产生缺页中断才能从磁盘中读取$a_{1,0}$。访问整个数组需要产生1024×1024次缺页中断，所以开销比较大。

而对于程序2，首先产生中断从磁盘中读取第一行数据，访问$a_{0,0}$，然后访问$a_{0,1}$，两者在同一个页中，具有很好的空间局部性和时间局部性，在同一行数据访问时，都不会产生中断。一共只会产生1024次缺页中断。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191016134829.png)

**基本概念：**

可以在页式和段式内存管理的基础上实现。

- 在转入程序时，不必将其全部装入到内存，而只将当前需要执行的部分的代码和数据装入到内存中，就可让程序开始执行；
- 在程序执行过程中，如果需执行的指令或访问的数据尚未在内存（称缺页或缺段），则由处理器通过操作系统将相应的页面或段调入到内存，然后继续执行程序；
- 另一方面，操作系统将内存中暂时不使用的页面或段调出保存在外存上，从而腾出更多空闲空间存放将要装入的程序以及将要调入的页面或段。

虚存技术基本特征：

- 大的用户空间：通过把物理内存与外存相结合，提供给用户的虚拟内存空间通常大于实际的物理内存，即实现了这两者的分离。如32位的虚拟地址理论上可以访问4GB，而可能计算机上仅有256M的物理内存，但磁盘容量大于4GB。
- 部分交换：与交换技术相比较，虚拟存储的调入和调出是对部分虚拟地址空间进行的；
- 不连续性：物理内存分配的不连续，虚拟地址空间使用的不连续。

#### 虚拟页式内存管理

页式内存管理回顾：

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191016140647.png)

大部分虚拟存储系统都采用虚拟页式管理技术，即在页式存储管理的基础上，增加**请求调页和页面置换**功能。

基本思路：

- 当一个用户程序要调入内存运行时，不是将程序的所有页面都装入内存，而是只装入部分的页面，就可启动程序运行。
- 在运行的过程中，如果发现要运行的程序或要访问的数据不在内存，则向系统发出缺页中断请求，系统在处理这个中断时，将外存中相应的页面调入内存，使得该程序能够继续运行。

**页表表项：**

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191016141828.png)

- 驻留位：表示该页是在内存还是外存。如果该位等于1，表示该页位于内存当中，即该页表项是有效的，可以使用；如果该位等于0，表示该页当前还在外存中，如果访问该页表项，将导致缺页中断；
- 保护位：表示允许对该页做何种类型的访问，如只读、可读写、可行等；
- 修改位：表明此页在内存中是否被修改过。当前系统回收该物理页面时，根据此位来决定是否把它的内容写回外存；如果该位为0，则该页没有被修改，跟硬盘中的数据一样，如果将该页换掉的话，直接释放就行，因为数据跟硬盘中的数据一样，下次需要时直接从硬盘读取就可以。
- 访问位：如果该页面被访问过，则设置此位。用于页面置换算法。置换页面时，尽量将没有访问的页面换出去，所以根据该位来判断，如果该位位0，表示没有被访问。

**缺页中断处理过程：**

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191016143324.png)

- 如果在内存中由空闲的物理页面，则分配一个物理页帧f，然后转到第4步；否则转第2步；
- 采用某种页面置换算法，选择一个将被替换的物理页帧f，它所对应的逻辑页为q。如果该页在内存期间被修改过，则需要把它写回外存；
- 对q所对应的页表项进行修改，把驻留位改为0；
- 将需要访问的页p装入到物理页面f当中；
- 修改p所对应的页表项的内容，把驻留位改为1，把物理页帧号置为f；
- 重新运行被中断的指令。

**后备存储（Backing Store）：**

在何出保存未被映射的页？

- 能够简单地识别在二级存储器中的页
- 交换空间

概念：

- 一个虚拟地址空间的页面可以被映射到一个文件（在二级存储中）中的某个位置；
- 代码段：映射到可执行二进制文件；
- 动态加载的共享库程序段：映射到动态调用的库文件；
- 其他段：可能被映射到交换文件（swap file），程序在运行过程中，没有对应到数据文件、库文件、执行文件，动态产生的一些数据，这些数据占了很大的空间，且需要换出到硬盘中，操作系统会在硬盘中开出一个区域swap（换入换出分区），这个区域来放置没有文件对应的内存的内容。

这四类组成了后背存储，或者二级存储。有了二级存储支持，使得虚存管理可以充分保证空间的有效性。

#### 虚拟内存性能

为了便于理解分页的开销，使用有效存储器访问时间effective memory acces time(EAT):

EAT = 访存时间 × 页表命中几率 + page fault处理时间 × page fault 几率

例子：

访存时间： 10ns

磁盘访问时间： 5ms = 5 000 000ns

参数 p = page fault几率 （缺页的几率）

参数 q = dirty page 几率（页面被修改过的几率）

则：EAT = 10(1-p) + 5 000 000 p(1+q)

对于没有缺页时，访问时间位10ns；对于缺页时，需要磁盘访问，同时如果内存中的页面被修改过，还需要将该页的数据写回到磁盘中，需要增加一个次磁盘的访问，所以需要乘以1+q。

公司的右侧5 000 000远远大于10，但p足够小，就可以接近10ns。程序具有局部性特点，即意味着程序缺页的次数特别少，比如说在访问一个页是重复访问4K页，访问100万多次，然后才访问硬盘中的数据，这样缺页才产生一次。

## 页面置换算法

功能：当缺页中断发生，需要调入新的页面而内存已满时，选择内存当中哪个物理页面被置换。

目标：尽可能地减少页面的换进换出次数（即缺页中断的次数）。具体来说，把未来不再使用的或短期内较少使用的页面换出，通常只能在局部性原理指导下依据过去的统计数据来进行预测。

页面锁定：用于描述必须常驻内存的操作系统的关键部分或时间关键的应用进程。实现的方法是：在页表中添加锁定标志位。

记录一个进程对页面访问的一个轨迹：

举例：虚拟地址跟踪（页号，偏移）

(3,0), (1,9), (4,1), (2,1)，(5,3), (2,0), (1,9), (2,4), (3,1), (4,8)

生成页面轨迹：(考虑页面置换算法，可以把偏移去掉，只有当一个页不存在时，才会考虑页面置换算法)

3， 1，4，2，5，2，1，2，3，4（替换如c，a，d，b，e，b，a，b，c，d）

模拟一个页面置换的行为并且记录产生页缺失的数量：

更少的缺失，更好的性能。

### 最优页面置换算法

**基本思路**：当一个缺页中断发生时，对于保存在内存当中的每一个逻辑页面，计算在它的下一次访问之前，还需要等待多长时间，从中选择等待时间最长的哪个，作为置换的页面。

这只是一种理想情况，在实际系统中是无法实现的，因为操作系统无从知道每一个页面要等待多长时间以后才会再次被访问。

该算法可用作其他算法的性能评价的一句（在一个模拟器上运行某个程序，并记录每一次的页面访问情况，在第二遍运行时即可使用最优算法）。

例子：

置换的页面是将来最长时间不需要的页面。

当前操作系统给程序分配了4个物理页帧，访问的页有5个。

在0时刻，物理页帧存储了abcd4个虚拟页，所以在前四次不会产生缺页中断。而在第5次访问时，e在物理页帧中没有对应，所以产生缺页中断，需要置换页。最长时间不需要访问的页是d，所以把d置换出去。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191017094735.png)

### 先进先出算法FIFO

**基本思路：**选择在内存中驻留时间最长的页面并淘汰之。具体来说，系统维护这一个链表，记录了所有位于内存当中的逻辑页面。从链表的排列顺序来看，链首页面的驻留时间最长，链尾页面的驻留时间最短。当发生一个缺页中断时，把链首页面淘汰出局，并把新的页面添加到链表的末尾。

性能较差，调出的页面有可能是经常要访问的页面，并且有Belady现象。FIFO算法很少单独使用。

Belady现象：当给一个程序分配更多的物理页时，采用FIFO时，给的物理页帧越多，产生缺失的次数更多。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191017095633.png)

假设0时刻，4个页帧的顺序为a->b->c->d，所以在5时刻，产生缺页中断，置换的页面是a，并且将a从链表中删除，将e加入链表，得到4个页帧的顺序b->c->d->e。依此类推。6时刻没有缺页中断，7时刻产生缺页中断，将b置换出去。

### 最近最久未使用算法（LRU）

Least Recently Used

**基本思路：**当一个缺页中断发生时，选择最久未使用的那个页面，并淘汰之。

它是对最优页面置换算法的一个近似，其依据是程序的局部性原理，即在最近一小段时间（最近几条执行）内，如果某些页面被频繁地访问，那么在将来的一小段时间内，它们还可能会再一次被频繁地访问。反过来说，如果在过去某些页面长时间未被访问，那么在将来它们还可能会长时间得不到访问。

例子：

置换的页面是最长时间没有被访问的。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191017100653.png)

对于1-4时刻，都不会产生缺页中断，对于5时刻，由于页表中没有对应的项，所以产生缺页中断，置换的页面是c，因为c最近被访问的时刻是1，是未被使用时间最久的页面。

LRU算法需要记录各个页面使用时间的先后顺序，**开销比较大**。两种可能的实现方法是：

- 系统维护一个页面链表，最近刚刚使用过的页面作为首节点，最久未使用的页面作为尾节点。每一次访问内存时，找到相应的页面，把它从链表中摘下来，再移动到链表之首。每次缺页中断发生时，淘汰链表末尾的页面。
- 设置一个活动页面栈，当访问某页时，将此页号压入栈顶，然后考察栈内是否有与此页面相同的页号，若有则抽出。当需要淘汰一个页面时，总是选择栈底的页面，它就是最久未使用的。

保持一个最近使用页面的“栈”：

上面的例子使用栈实现的过程。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191017101515.png)

### 时钟页面置换算法

Clock页面置换算法，LRU的近似，对FIFO的一种改进。

**基本思路：**

- 需要用到页表项当中的访问位，当一个页面被转入内存时，把该为初始化未0。然后如果这个页面被访问（读/写），则把该位置为1（置1的过程由硬件完成）。
- 把各个页面组织环形链表（类似钟表面），把指针指向最老的页面（最先进来）；
- 当发生一个缺页中断时，考察指针所指向的最老页面，若它的访问位为0，立即淘汰；若访问位为1，则把该位置为0，然后指针往下移动一格。如此下去，直到找到被淘汰的页面，然后把指针移动到它的下一格。

维持一个环形页面链表保存在内存当中

- 用一个时钟（或者使用/引用）位来标记一个页面是否经常被访问
- 当一个页面被使用时，这个位被设置位1

时钟头扫遍页面寻找一个带有used bit = 0

- 替换在一个周转内没有被使用过的页面



![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191017102411.png)

假设有5个物理页帧，有8个虚拟页。01347这五个虚拟页存放在物理内存中。第一个位表示是否存在物理内存中，第二个位表示是否被访问过。第三位是页帧号。

首先，指针指向上次访问的位置，程序正常运行，当遇到缺页中断时，需要将新的换入到物理内存中。从当前指针指向的页表项开始看，虚拟页0对应的页表项，第二位为1，表示最近刚被访问过，则将其置为0；并将指针指向下一个，同样第二位为1，将其置为0；再指向下一个页表项，第二位为0，将其置换出去，假设访问的是虚拟页6，则将虚拟页1对应的物理页5中的内容替换为虚拟页6对应的内容。

例子：

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191017104251.png)

对于1-4时刻，将abcd访问一遍，所以将其used bit都置为了1。

5时刻，物理页没有空闲，而且e不在页表项中，所以产生中断进行页面置换，此时指针旋转一遍，将used bit全部置为0，回到a时，used bit为1，所以将a置换出去，同时e被访问，将used bit置为1，最后将指针指向下一项。

6时刻访问b，在页表项中，所以不会产生中断，只需将used bit置为1。

7时刻，a不在页表项中，所以指针寻找used bit为0的页表项，目前指针指向b，used bit为1，将其置为0，并指向下一项，此时为c的used bit为0，所以将其置换出去，并且将used bit置为1，最后将指针指向下一项。

8时刻，b在页表项中，直接访问即可，并将used bit设置为1。

。。。

产生了4次缺页中断，比LRU差一些，跟FIFO差不多。实际中，跟LRU接近的。

### 二次机会

used bit包括读和写，还有一个bit即dirty bit，即表示发生过写，dirty bit=1，由硬件完成。

如果某个页从硬盘读到内存，如果全部是读操作，这样内存中的内容和硬盘中的内容相同，发生置换时，直接将内存的内容释放即可，无需写回到硬盘中。如果发生过写操作，这样内存中的数据和硬盘中的数据不一致，发生置换时，需要写回到硬盘中。

dirty bit可用来clock算法，来提出更高效的clock算法，即二次机会法。将两个bit都用上，减少对硬盘的访问次数。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191018110535.png)

只有当used bit和dirty bit都为0，才将其替换出去。

如果used bit为0，dirty bit为1，将dirty bit变为1；如果used bit为1，dirty bit为0，将used bit变为0;

如果used bit和dirty bit都为1，将used bit变为0。

被写过的页有更大的机会留在内存中，减少了对硬盘的访问次数。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191018112628.png)

首先在0时刻，abcd4个虚拟页都被读过，但没有被写。经过1-4时刻，其中a和b被写过，所以a,b对应的标识位标称了11。

对于5时刻，虚拟页e在内存中不存在，所以需要置换，通过一遍遍历发现没有标识位为00，再一次遍历时，c的标识位变成了00，所以将c置换出去；并且e被读了，所以标识位标变成了10。

对于6时刻，内存中有虚拟页6，所以直接读取b。

对于时刻7，同样内存中有虚拟页a，于是写入a中，并将a的标识位置为11。

。。。

### 最不常用算法LFU

Least Frequently Used

**基本思路：**当一个缺页中断发生时，选择访问次数最少的那个页面，并淘汰之。

实现方法：对每个页面设置一个访问计数器，每当一个页面被访问时，该页面的访问计数器加1。在发生缺页中断时，淘汰计数值最小的那个页面。

LRU和LFU的区别：LRU考察的是多久未访问，时间越短越好；而LFU考察的访问次数或频度，访问次数越多越好。

**问题：**一个页面在进程开始时使用得很多，但以后就不使用了，实现也费时费力。

解决办法：定期把次数寄存器右移一位。

练习题：

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191018131141.png)

### Belady现象

Belady现象：在采用FIFO算法时，有时会出现分配的物理页面数增加，缺页率反而提高的异常现象。

Belady现象的原因：FIFO算法的置换特征与进程访问内存的动态特征是矛盾的，与置换算法的目标是不一致的（即替换较少使用的页面），因此，被它置换出去的页面并不一定是进程不会访问的。

#### 对于FIFO算法

当分配3个物理页时：

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191018132355.png)

如果分配4个物理页时：

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191018132516.png)

从上面可以看出，3个物理页时产生9次缺页中断，而4个物理页时产生10次缺页中断。

#### 对于LRU

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191018132928.png)

从上图可以看出，LRU算法在没有Belady现象。

LRU符合栈算法的特点。FIFO不满足栈算法的特点。

Clock算法和二次机会算法是否会产生Belady现象？

### LRU、FIFO、Clock算法比较

LRU算法和FIFO本质上都是先进先出的思路，可以通过链表和栈来表示访问的次序。

- LRU除了驻留时间还考虑页面的最近访问时间来排序。所以需要在每一次页面访问的时候动态调整各个页面之间的先后顺序（有一个页面的最近访问时间变了）；
- FIFO是针对页面进入内存的时间来进行排序的，这个时间是固定不变的，所以各个页面之间的先后顺序是固定的。如果一个页面在进入内存后没有被访问，那么它的最近访问就是它进入内存的时间。换句话说，如果内存当中的所有页面都未曾访问过，那么LRU算法就是退化的FIFO算法。

Clock算法是对LRU算法的近似，利用一个bit来实现。

算法只是一个环节，除了算法本身，对于访问序列也有要求，需要具有局部性。如果序列不具备局部性，那么这些算法就没有区别了。

LRU算法性能较好，但系统开销大；FIFO算法开销较小，但可能会发生Belady现象。因此，折中的办法就是Clock算法，在每一次页面访问时，它不必动态地调整页面在链表中的顺序，而仅仅是做一个标记，然后等待发生缺页中断的时候，再把它移动到链表末尾。对于内存当中那些未被访问的页面，Clock算法的表现和LRU算法一样好；而对于那些曾经被访问过的页面，它不能像LRU算法那样，记住它们的准确位置。

### 局部页面置换算法的问题、工作集模型

下面是一个FIFO页面置换算法的例子，第一次分配3个物理页，第二次分配4个物理页。

可以看出，第一次存在9次缺页，而对于第二次才1次缺页。物理页帧的大小对页面置换算法的效果产生很大的影响。

如果给一个程序分配一个固定的物理页帧，在某种程度上限制了程序它产生缺页的特点。程序在运行过程中有阶段性，在开始可能需要很多内存，中间一段时间需要很少内存，最后可能也需要很大的内存，是一个动态变化的过程。对物理页帧的需求是可变。前面对于物理页帧的分配都是固定的。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191018140853.png)

但是一个操作系统里面可以跑多个程序，给每个程序分配固定的物理页帧，就限制了灵活性。根据程序的运行不同阶段，动态分配物理页帧，这就是全局页面置换算法考虑的问题。

#### 工作集模型

前面介绍的各种页面置换算法，都基于一个前提，即个程序的局部性原理。

如果局部性原理不成立，那么各种页面置换算法就没有区别，也没有意义。

如果局部性原理成立，那么如何来证明它的存在，如何来对它进行定量分析？这就是**工作集模型**。

工作集（working set）：一个进程当前正在使用的逻辑页面集合

可用一个二元函数$W(t,\Delta)$表示：

t是当前的执行时刻

$\Delta$称为工作集窗口（working-set window），即一个定长的页面访问的时间窗口

$W(t,\Delta)=$在当前时刻t之前的$\Delta$时间窗口当中的所有页面所组成的ejihe（随着t的变化，该集合也在不断地变化）；

$|W(t,\Delta)|$指工作集的大小，即页面数目。

一个例子：

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191018142452.png)

可以看出$t_2$为起始时间的工作集局部性好，一直重复访问3和4。

工作集大小的变化：进程开始执行后，随着访问新页面逐步建立比较稳定的工作集。当内存访问的局部性区域的位置大致稳定时，工作集大小也大致稳定；局部性区域的位置改变，工作集快速扩张和收缩过渡到下一个稳定值。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191018142904.png)

#### 常驻集

常驻集：是指在当前时刻，进程实际驻留在内存当中的页面集合。

- 工作集是进程在运行过程中固有的性质，而常驻集取决于系统分配给进程的物理页面数目，以及所采用的页面置换算法。

- 如果一个进程的整个工作集都在内存当中，即常驻集等于工作集，那么进程将很顺序地进行，而不会造成太多的缺页中断（直到工作集发生剧烈变动，从而过渡到另一个状态）。
- 当进程驻留集的大小到达某个数目之后，再给它分配更多的物理页面，缺页率不会明显下降。

## 两个全局置换算法

### 工作集页置换算法

在之前$\tau$个内存访问的页引用是工作集，$\tau$被称为窗口大小。

随着程序的执行，只要页不属于工作集窗口，即使没有产生缺页，也会被丢弃。

如果产生缺页，我们要置换不在工作集中的页面。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191018144537.png)

在0时刻，工作集中有dea，三个虚拟页，需要注意e的时刻t=-2，d的时刻t=-1。

在1时刻，c不在内存当中，产生缺页中断，将c写入内存当中，此时工作集变为：acde。

在2时刻，c在内存当中，直接读取即可，但是工作集变为dac，因为t=-2时刻距t=2超过了$\tau=4$，所以将e从工作集中删除，并且将该页从内存中删除。

在3时刻，d在内存当中，直接读取即可，但是工作集仍为acd。

....

这样可以确保物理内存中有足够多的页存在，从而可以给其他运行的程序足够多的内存，这样对于多个程序的层面。

### 缺页率页面置换算法

**可变分配策略：**常驻集大小可变。例如每个进程在刚开始运行的时候，先根据程序大小给它分配一定数目的物理页面，然后再进程运行过程中，再动态地调整常驻集的大小。

- 可采用**全局页面置换**的方式，当发生一个缺页中断时，被置换的页面可以是再其他进程当中，各个并发进程竞争地使用物理页面。
- 优缺点：性能较好，但增加了系统开销。
- 具体实现：可以使用缺页率算法（PFF, page fault frequency）来动态调整常驻集的大小。

**缺页率：**

缺页次数 / 内存访问次数

影响缺页率的因素：

- 页面置换算法
- 分配给进程的物理页数目
- 页面本身大小
- 程序的编写方法，局部性问题

缺页率算法：

缺页率高，增加工作集来分配工作的物理页面；缺页率地，减少工作集来减少它的物理页数。力图使运行的每个程序的缺页率保持在一个合理的范围内。

算法：

保持追踪缺失发生概率：

​	当缺失发生时，从上次页缺失起计算这个时间记录这个时间，$t_{last}$是上次的页缺失的时间。

​	如果发生页缺失之间的时间是“大”的，之后减少工作集。

​     如果$t_{current} - t_{last} > T $，之后从内存中移除所有在$[t_{current} - t_{last} ]$时间内没有被使用的物理页。

​     如果这个发生页缺失的时间“小”的，之后增加工作集。

​     如果$t_{current} - t_{last} < T $，之后仅增加缺失页到工作集中。



一个例子：

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191018151740.png)

在0时刻，物理内存中有ade三个虚拟页；

在1时刻，需要访问c，但是不在内存当中，所以产生缺页中断，但是这是第一次产生中断，所以我们不进行页的调整。

在2时刻，需要访问c，直接访问即可 ；

在3时刻，同样直接访问d即可；

在4时刻，由于b不在内存当中，所以产生缺页中断，将b读入到内存当中，由于当前产生缺页中断的时间距上次产生缺页中的时间等于3（大于2），所以需要将不在1和4时刻之间被使用过的页移除，即a,e。所以当前内存中有bcd三个页。

......

这两个算法是根据工作集和缺页率来动态调整内存中物理页的数量，这样可以确保整体上，经常访问的页驻留在内存当中。采用全局置换页算法优于局部置换页算法。

## 抖动问题

对刚才的工作集和常驻集的讲解。

如果分配给一个进程的物理页面太少，不能包含整个的工作集，即常驻集被包含于工作集，那么进程将会造成很多的缺页蒜蓉，需要频繁地在内存与外存之间替换页面，从而使进程的运行速度变得很慢，我们把这种状态称为**抖动**。

产生抖动的原因：随着驻留在内存的进程数目增加，分配给每个进程的物理页数不断 减少，缺页率不断提升。所以操作系统要选择一个适当的进程数目和进程需要的帧数，一遍再并发水平和缺页率之间达到一个平衡。

# 进程

## 进程描述(静态)

### 进程的定义

一个具有一定独立功能的个程序再一个数据集合上的一次动态执行过程。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191019193157.png)

### 进程的组成

- 程序的代码

- 程序处理的数据

- 程序计数器中的值，指示下一条运行的指令

- 一组通用的寄存器的当前值、堆、栈

- 一组系统资源（如打开的文件）

总之进程包含了正在运行的一个程序的所有状态信息。

**程序和进程的联系：**

- 程序是产生进程的基础
- 程序的每次运行构成不同的进程
- 进程是程序功能的体现
- 通过多次执行，一个程序可以对应多个进程；通过调用关系，一个进程可包含多个程序。

进程和程序是多对多的关系。

**程序和进程的区别：**

- 进程是动态的，程序是静态；程序是有序代码的集合；进程是程序的执行，进程有用户态和内核态（有些操作需要操作系统去完成，比如读取文件，进程向操作系统发起请求，操作系统代表进程在内核中执行，此时进程处于内核态）。
- 进程是暂时的，程序是永久的：进程是一个状态变化的进程，程序是长久保存的。
- 进程与程序的组成不同：进程的组成包含程序、数据和进程控制块（即进程状态信息）。】

**类比：**

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191019194339.png)

### 进程的特点

- 动态性：可动态创建、结束进程，还可以切换
- 并发性：进程可以被独立调度并占用处理机运行；
  - 并发：多个程序交替执行，强调一段时间内，交替执行，看上去是同时执行；
  - 并行：多个程序同时执行，强调同一时刻，同时执行，并行必须要求CPU是多核的。
- 独立性：不同进程的工作不相互影响；**页表**是保证进程独立性的机制，每个进程只能访问自己页表对应的内存，在读取物理地址之前会有自检。
- 制约性：因访问共享数据/资源或进程间同步而产生制约。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191019194944.png)

(a):进程之间有切换，动态垂心

(b):进程之间的地址空间是独立的

(c):进程相互之间有时间调度的关系

怎么设计OS来实现进程管理机制呢？

程序 = 算法 + 数据结构

操作系统也是一个程序。

描述进程的数据结构：进程控制块（Process Control Block, PCB）。

操作系统为每个进程都维护了一个PCB，用来保存与该进程有关的各种状态信息。

### 进程控制结构

进程控制块：操作系统管理控制进程运行所用的信息集合。

操作系统用PCB来描述进程的基本情况以及运行变化的过程，PCB是进程存在的唯一标识。

进程的创建：为该进程生成一个PCB

进程的终止：回收它的PCB

进程的组织管理：通过堆PCB的组织管理来实现

PCB具体包含什么信息？如何组织的？进程的状态切换？

**PCB包含三大类信息：**

-  进程标识信息：如本进程的标识，本进程的产生者标识（父进程标识），用户标识，那个程序在执行等等。
- 处理机状态信息保护区：保存进程的运行现场信息
  - 用户可见寄存器，用户程序可以使用的数据，地址等寄存器
  - 控制和状态寄存器，如程序计数器（PC），程序状态字（PSW）
  - 栈指针，过程调用/系统调用/中断处理和返回值需要用到它
- 进程控制信息
  - 调度和状态信息：用户操作系统调度进程并占用处理机使用。
  - 进程间通信信息：为支持进程间通信相关标识、信号等，这些信息存储在接收方的进程控制块中。
  - 存储管理信息：包含由指向进程映像存储空间的数据结构。
  - 进程所用资源：说明由进程打开、使用的系统资源，如打开的文件等。
  - 有关数据结构连接信息：进程可以连接到一个进程队列中，或连接到相关的其他进程的PCB。比如B是A的子进程，C是B的子进程，可以通过一个链表来表示它们的关系。

**PCB的组织方式：**

- 链表：同一状态的进程其PCB成一链表，多个状态对应多个不同的链表。进程是动态，存在删除、插入等等操作，采用链表效率更高。

  各状态的进程形成不同的链表：就绪链表，阻塞链表

- 索引表：同一状态的进程归入一个index表（由index指向PCB），多个状态对应多个不同的index表。

  各状态的进程形成不同的索性表：就绪索引表，阻塞索引表

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191019201032.png)

目前更多采用基于链表的组织方式。如果进程个数比较固定，不会由频繁创建和删除的过程，采用索引表组织也是一种好办法。所以说，根据操作系统特点，是通用的操作系统，还是特殊的操作系统，可以采用不同的PCB组织方式。

## 进程状态(动态)

### 进程的生命周期

- 进程创建

  进程创建的3个主要事件：

  - 系统初始化，第一个进程，NIT进程，这个进程再负责创建其他新的进程（下面两个）
  - 用户请求创建一个新进程
  - 正在运行的进程执行了一个创建进程的系统调用

  在内存中创建一个PCB，完成一系列初始化工作。

- 进程运行

  内核选择一个就绪的进程，让它占用处理机并执行

  如何选择？调度算法

- 进程等待

  在以下情况，进程等待（阻塞）：

  - 请求并等待系统服务，无法马上完成，比如文件读写
  - 启动某种操作，无法马上完成，比如和其他程序协同执行，等待其他执行完成
  - 需要的数据没有到达

  **进程只能自己阻塞自己**，因为只有进程自身才能知道何时需要等待某种事件的发生。

- 进程唤醒

  唤醒进程的原因：

  - 被阻塞进程需要的资源可被满足
  - 被阻塞进程等待的事件到达
  - 将该进程的PCB插入到就绪队列

  **进程只能被别的进程或操作系统唤醒。**

- 进程结束

  在以下四种情形下，进程结束：

  - 正常退出（自愿的）
  - 错误退出（自愿的）
  - 致命错误（强制性的）
  - 被其他进程所杀（强制性的），比如管理进程，觉得该进程占用内存太多，将其杀死

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191019202252.png)

### 进程状态变化模型

进程的三种基本状态：

进程在生命结束前处于且仅处于三种基本状态之一。

不同系统设置的进程状态数目不同。

- 运行状态：当一个进程正在处理机上运行时。
- 就绪状态：一个进程获得了除处理机之外的一切所需资源，一旦得到处理机即可运行。
- 等待状态（又称阻塞状态locked）：一个进程正在等待某一个事件而暂停运行。如等待某资源，等待输入/输出完成。

进程其他的基本状态：

- 创建状态：一个进程正在被创建，还没被转到就绪状态之前得状态
- 结束状态：一个进程正在从系统中消失时的状态，这是因为进程结束或由于其他原因所导致。

状态变化图：

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191020153401.png)

## 进程挂起

进程在挂起状态时，意味着进程没有占用内存空间。处在挂起状态的进程映像在磁盘上。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191020153914.png)

挂起状态：

- 阻塞挂起状态：进程在外存并等待某事件的出现；
- 就绪挂起状态：进程在外存，但只要进入内存，即可运行。

与挂起相关的状态转换：

挂起：把一个进程从内存转到外存，可能存在以下几个情况：

- 阻塞态到阻塞挂起：没有进程处于就绪状态或就绪进程要求更多内存资源时，会进行这种转换，以提交新进程或运行就绪进程。
- 就绪态到就绪挂起：当有高优先级阻塞（系统认为很快会就绪的）进程和低优先就绪进程时，系统会选择挂起低优先级就行进程。这是因为高优先级阻塞态进程变成就绪态时，会在低优先级的就绪进程之前，会优先执行。
- 运行态到就绪挂起：对抢先式分时系统，当有高优先阻塞挂起进程因事件出现而进入就绪挂起时，系统可能会把运行进程转到就绪挂起状态。

在外存时的状态转换：

- 阻塞挂起到就绪挂起：当有阻塞挂起进程因相关事件出现时，系统会把阻塞挂起进程转换为就绪挂起进程。随着程序执行，阻塞挂起进程的资源得到了满足，应该变成就绪态，但是程序还在外存，所以还应该是就绪挂起，只是改变状态。

与挂起相关的状态转换：

解挂/激活（Activate）：把一个进程从外存转到内存；可能有以下几种情况：

- 就绪挂起到就绪：没有就绪进程或挂起就绪进程优先级高于就绪进程时，会进程该转换。
- 阻塞挂起到阻塞：当一个进程释放足够内存时，系统会把一个高优先级阻塞挂起进程转换为阻塞进程。

**OS怎么通过PCB和定义的进程状态来管理PCB，帮助完成进程的调度过程？**

状态队列

- 由操作系统来维护一组队列，用来表示系统当前所有进程的当前状态；

- 不同的状态分别用不同的队列表示；

- 每个进程的PCB都根据它的状态加入到相应的队列当中，当一个进程的状态发生变化时，它的PCB从一个状态队列脱离出来，加入到另一个队列。

每个状态存在多个队列，用来对应不同的优先级。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191020160641.png)

## 线程

### 为什么需要线程？

举例分析：MP3的实现，播放音乐包括三个过程：读取文件、解压文件、播放

单进程实现：

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191027155527.png)

多进程实现：

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191027155721.png)

怎么来解决这些问题？

提出一种新的实体，满足一下特性：

- 实体之间可以并发地执行
- 实体之间共享相同的地址空间

这就是线程。

### 什么是线程？

从资源角度来看，进程是用来管理地址：地址空间、打开的文件、网络

从运行的角度来看，代码在这个资源平台上的一条执行流程（线程）。

进程有自己的进程控制块（Thread control block）TCB。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191027160131.png)

线程共享代码段和数据段，每个线程有自己的TCB，记录运行代码的逻辑。

**线程 = 进程 - 共享资源**

线程的优点：

- 一个进程中可以同时存在多个线程；
- 各个线程之间可以并发地执行；
- 各个线程之间可以共享地址空间和文件等资源。

缺点：

- 一个线程崩溃，会导致所属进程的所有线程崩溃。

浏览器通过进程来实现的，因为其需要可靠性，不能让一个网页崩溃，影响其他网页。

线程所需的资源：

多线程中每个线程都有各自的堆栈和寄存器。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191027160539.png)

线程和进程的比较：

-  进程是资源分配单位，线程是CPU调度的单位；
- 进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；
- 线程同样具有就绪、阻塞和执行三种基本状态，同样具有状态之间的转换；
- 线程能减少并发执行的时间和空间开销：
  - 线程的创建时间比进程短
  - 线程的终止时间比进程短
  - 同一进程内的线程切换时间比进程短：线程切换不需要切换页表，而进程切换需要
  - 由于同一进程的各线程共享内存和文件资源，可直接进行不通过内核的通信

### 线程的实现方式

- 用户线程：操作系统看不见的，由应用程序库来管理

- 内核线程：操作系统管理的

用户线程与内核线程的对应关系：

- 多对一
- 一对一
- 多对多

#### 用户线程

在用户看嘛实现的线程机制，它不依赖于操作系统的内核，有一组用户级的线程库函数来完成线程的管理，包括进程的创建、终止、同步和调度等。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191027161532.png)

- 由于用户线程的维护由相应进程来完成（通过线程库函数），不需要操作系统内核了解用户线程的存在，可用于不支持线程技术的多进程操作系统；
- 每个进程都需要它自己私有的线程控制块（TCB）列表，用来跟踪记录它的各个线程的状态信息（PC、栈指针、寄存器），TCB由线程库函数来维护；
- 用户线程的切换也是由线程库函数来完成的，无需用户态/内核态切换，所以速度特别快；
- 允许每个进程拥有自定义的线程调度算法。

用户线程缺点：

- 阻塞性的系统调用如何实现？如果一个线程发起系统调用而阻塞，则整个进程在等待；
- 当一个线程开始运行后，除非它主动交出CPU的使用权，否则它所在的进行当中的其他线程将无法运行；
- 由于时间片分配给进程，故于其他进程比，在多线程执行时，每个线程得到的时间片较少，执行会较慢。

#### 内核线程

windows操作系统采用内核线程。

内核线程是指在操作系统的内核当中实现的一种线程机制，有操作系统的内核来完成线程的创建、终止和管理。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191027162225.png)

线程是CPU的调度单位，进程完成资源的管理。

- 在持支内核线程的操作系统中，由内核来维护进程和线程的上下文信息（PCB和TCB）。
- 线程的创建、终止和切换都是通过系统调用/内核函数的方式来进行，由内核来完成，因此系统开销较大；
- 在一个进程中，如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程的运行；
- 时间片分配给线程，多线程的进程获得更多的CPU时间；
- Windows NT和Windows 2000/XP支持内核线程。

#### 轻量级进程

它是内核支持的用户线程，一个进程可有一个或多个轻量级进程，每个轻量级进程有一个单独的内核线程来支持。

LInux系统采用该种方式。

## 上下文切换

进程的上下文切换。切换进程所用的寄存器，栈指针寄存器、程序寄存器等等。进程切换的将上下文写入进程控制块PCB中的某个位置。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191028103419.png)

## 创建进程

fork() 创建一个继承的子进程

- 复制父进程的所有变量和内存
- 复制父进程的所有CPU寄存器(有一个寄存器例外)

fork()的返回值

- 子进程的fork()返回0
- 父进程的fork()返回子进程标识符
-  fork() 返回值可方便后续使用，子进程可使用getpid()获取PID

```c++
int pid = fork()；		// 创建子进程
if(pid == 0) {			// 子进程在这里继续
     // Do anything (unmap memory, close net connections…)
	exec(“program”, argc, argv0, argv1, …);
}else if(pid < 0)
{
	printf("error!");
}
else
{
    printf("Whose your daddy?");
    //...
    child_status = wait(pid); //等待子进程结束
}
```

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191028105419.png)

exec()调用允许一个进程加载一个不同的程序并且在main开始执行。

执行的exec()时，程序本身的代码段和堆栈会被覆盖。

fork()的简单实现：

- 对子进程分配内存
- 复制父进程的内存和CPU寄存器到子进程里
- 开销昂贵！！

在99%的情况里，我们在调用fork()之后调用exec()：

- 在fork()操作中内存复制是没有复制的
- 子进程将可能关闭打开的文件和连接
- 开销因此是高的

vfork()

- 一个创建进程的系统调用，不需要创建一个同样的内存映像
- 一些时候称为轻量级fork()
- 子进程应该几乎立即调用exec()

现在不在使用vfork()技术，因为存在了**Copy on Write(COW)**技术。通过虚存管理，来实现的。即写的时候在复制。

并没有真实复制整个地址空间，而是仅仅复制地址空间的页表，指向同一块地址空间。当父进程或子进程对某一个地址单元进行写操作时，触发一个异常，使得父进程和子进程将触发异常的页复制成两份。如果只是只读，就不需要复制，因为使用同一块数据。不管执不执行exec，fork()还是创建一个子进程，只复制了页表，根据是否有写操作来进行复制。

## 进程等待和终止

wait()系统调用是被父进程用来等待子进程的结束。

一个子进程向父进程返回一个值，所以父进程必须接受这个值并处理。

wait()系统调用担任这个要求：

- 它使父进程去睡眠来等待子进程的结果；
- 当一个子进程调用exit()的时候，操作系统解锁父进程，并且将通过exit()传递得到的返回值作为wait()调用的一个结果（连同子进程的pid一起），如果这里没有子进程存活，wait()立刻返回；
- 当然，如果这里有为父进程的僵尸等待，wait()立即返回其他一个值（并且解锁僵尸状态）。

子进程的PCB释放需要父进程来进行，所以需要wait()等待，让子进程结束后，父进程才结束。

进程结束执行之后，它调用exit()。

这个系统调用：

- 将程序的结果作为一个参数
- 关闭所有打开的文件，连接等等
- 释放内存
- 释放大部分支持进程的操作系统结构
- 检查是否父进程存活着的：
  - 如果是的话，它保留结果直到父进程需要它；在这种情况里，进程没有真正死亡，但是它进入了僵尸状态；
  - 如果没有，它释放所有的数据结构，这个进程死亡。这个由系统根进程（第一个创建的进程init）来代替父进程释放PCB。
- 清理所有等待的僵尸进程

进程控制的4个主要相关的系统调用与进程状态的关系：

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191028122644.png)

调用exec()时，对应不同状态。

## 调度算法

状态之间的转化，都会触发调度。

内核运行调用程序的条件：（满足一条即可）

- 一个进程从运行状态切换到等待状态
- 一个进程被终结了

不可抢占：

- 调度程序必须等待时间结束，一个进程处于阻塞状态，另一个进程不得不等待上一个进程执行完后再执行。

可以抢占：

- 调度程序在中断被响应后执行
- 当前的进程从运行切换到就绪，或者一个进程从等待切换到就绪
- 当前运行的进程可以被换出

用户态可以抢占，内核态可抢占。

### 调度原则

- CPU使用率
- 吞吐量
- 周转时间：一个进程从初始化到结束，包括所有等待时间所花费的时间，周转时间=等待时间+处理时间
- 等待时间：进程在就绪队列中的总时间
- 响应时间：从一个请求被提交到产生第一次响应所花费的总时间

具体的平均原则：

- 减少响应时间：及时处理用户的输出并且尽快将输出提供给用户
- 减少平均响应时间的波动
- 增加吞吐链
  - 减少开销
  - 系统资源的高效利用
- 减少等待时间：减少每个进程的等待时间

- 低延迟调度增加了交互式表现
- 但是操作系统需要保证吞吐链不受影响
- 吞吐量是操作系统的计算带宽
- 响应时间是操作系统的计算延迟

公平的定义：

举例：

- 保证每个进程占用相同的CPU时间
- 这公平么？如果一个用户比其他用户运行更多的进程怎么办

举例：

- 保证每个进程都等待相同的时间

公平通常回增加平均响应时间。

### 通用计算机调度算法

#### FCFS(先来先服务)

如果进程在执行中阻塞，队列中的第一个会得到CPU。

举例：3个进程，计算时间分别为12、3、3

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191101143543.png)

优点：简单

缺点：

- 平均等待时间波动大
- 花费时间少的任务可能排在花费时间长的任务后面
- 可能导致I/O和CPU之间重叠处理

#### SJF(短作业优先)

按照预测完成时间来将任务入队

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191101144026.png)

就绪队列中的进程按照预测时间进行了排序。

可以是抢占的或者不抢占的：

- 不抢占的：如果一个进程在执行过程中，来一个新的进程，而且新的进程执行时间比当前执行的进程时间还要短，采取的策略是不打断当前执行的进程，而是放入就绪队列的开头
- 抢占的：如果当前进程的需要9个时间片，而刚执行完成一个时间片，并且新来的进程只需要5个时间片，采取的策略则是打断当前执行的进程，从运行态变成就绪态，而新来的进程占用CPU执行。也成为SRT(最短剩余时间)。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191101144757.png)

存在的问题：

- 可能导致饥饿
  - 连续的短任务流使长任务饥饿
  - 短任务可用时的任何长任务的CPU时间都会增加平均等待时间
- 需要预知未来
  - 怎么预估下一个CPU突发的持续时间
  - 简单的解决办法：询问用户
  - 如果用户欺骗就杀死进程
  - 如果用户不知道怎么办

根据过去来预测未来。

#### HRRN(最高响应比优先)

- 在SPN调度的基础上改进

- 不可抢占

- 关注进程等待了多长时间

- 防止无限期推迟

调度原则：选择R值（响应比）最高的进程
$$
R=(w+s)/s \\
w：等待时间，s执行时间
$$

#### Round Robin(轮询)

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191101150559.png)



RR开销：额外的上下文切换

时间片太大：

- 等待时间过长
- 极限情况退化成FCFS

时间片太小：

- 反应迅速，但是....
- 吞吐量由于大量的上下文切换开销受到影响

目标：

- 选择一个合适的时间片
- 经验规则：维持上下文切换开销处于1%以内

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191101150917.png)

#### Multilevel Feedback Queues(多级反馈队列)

就绪队列划分成独立的队列：

- 前台（交互） 
- 后台（批处理）

每个队列拥有自己的调度策略：

- 前台：RR
- 后台：FCFS

调度必须在队列间进行：

- 固定优先级
  - 先处理前台，然后处理后台
  - 可能导致饥饿
  - 进程可能是动态变化，比如从前台变成后台
- 时间切片
  - 每个队列都得到一个确定的能够调度其进程的CPU总时间
  - Eg：80%给使用RR的前台，20%给使用FCFS的后台

一个进程可以在不同的队列中移动。

进程是一个开始前台进程，优先级比较高，运算结束，会有大量的IO处理，等待时间较长，这样可以将其优先级提高。过一段时间，做完交互后，需要大量计算，是CPU密集，时间片用得比较快，用完一个时间片，将其优先级降低一级，逐渐移动到优先级比较低的队列中。交互性进程可以放在优先级比较到的队列中。

例如：n级优先级---优先级调度在所有级别中，RR在每个级别中

- 时间片大小随优先级级别增加而增加
- 如果任务在当前的时间片中没有完成，则降到下一个优先级

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191101151718.png)

#### Fair Share Scheduling(公平共享调度)

主要针对多人共享一台计算机时使用。

Linux采用了公平调度策略。

#### 总结

-  FCFS
  - 不公平，平均等待时间较差
- SPN/SRT短进程优先
  - 不公平，但是平均等待时间最小
  - 需要精确预测计算时间
  - 可能导致饥饿
- HRRN最高响应比优先
  - 基于SPN调度改进
  - 不可抢占
- RR轮询
  - 公平，但是平均等待时间较差
- MLFQ 多级反馈队列
  - 和SPN类似
- FSS公平共享调度
  - 公平是第一要素

### 实时调度

实时调度一般用于实时系统，用在工业控制，比如火车、机床等等。规定时间完成一定任务。

- 强实时系统：需要在保证的时间内完成重要的任务，必须完成

- 弱实时系统：要求重要的进程的优先级更高，尽量完成，并费必须

任务（工作单元）：一次计算、一次文件读取、一次信息传递等等

#### RM速度单调调度

#### EDF最早期限调度

### 多处理器调度

多处理器的CPU调度更加复杂。

对称多处理器(SMP)。

### 优先级反转问题

$T_3$、$T_1$、$T_2$三者优先级从低到高。$t_1$时刻$T_3$进入开始执行，到$t_2$时刻开始读取缓冲区，缓冲区被上锁，直到$t_3$时刻，$T_1$进程进入，由于其优先级高于$T_3$，所以$T_1$开始执行，到$t_4$时刻，$T_1$同样需要读取缓冲区，但是缓存区被$T_3$上锁导致无法读取，所以$T_3$继续执行。到了$t_5$时刻，进程$T_2$进入，由于$T_2$优先级高于$T_3$，所以$T_2$开始执行，直到$T_2$执行完毕。这是$T_3$继续执行，$T_3$完成缓冲区读取，将缓冲区解锁，由于$T_1$的优先级高于$T_3$，所以$T_1$继续执行。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191101171904.png)

解决办法：

- 优先级任务继承高优先级任务的优先级依赖于他们的共享的资源
- 优先级天花板：“资源”的优先级和“所有可以锁定该资源的任务中的优先级最高的那个任务”的优先级相同
- 除非优先级高于系统中所有被锁定的资源的优先级上限，否则任务尝试执行临界区的时候会被阻塞
- 持有最高优先级上限信号量锁的任务，会继承被该锁所阻塞的任务的优先级。

## 同步

无论多个线程的指令序列怎么样交替执行，程序都必须正常工作。

### 概念

**原子操作**是指一次不存在任何中断或者失败的执行

- 该执行成功结束
- 或者根本没有执行
- 并且不应该发现任何部分执行的状态。

实际上操作往往不是原子的。

**临界区：**是指进程中的一段需要访问共享资源并且当另一个进程处于相应代码区域时便不会被执行的代码区域。

**互斥：**当一个进程处于临界区并访问共享资源时，没有其他进程会处于临界区并且访问任何相同的共享资源。

**饥饿：**一个可执行的进程，被调度器持续忽略，以至于虽然处于可执行状态却不被执行

**锁：**只能等待解锁后才能访问

**解锁：**使得可以访问之前被锁保护的物体类的东西

**死锁：**两个或以上的进程，在相互等待完成特定任务，而最终没法将自身任务进行下去。A拿到锁1，B拿到锁2，A想继续拿到锁2后再继续执行，B想继续拿到锁1后再继续执行。导致A和B谁也无法继续执行。

### 临界区

**互斥**：同一时间临界区中最多存在一个线程

**Progress：**如果一个线程想要进入临界区，那么它最终会成功

**有限等待**：如果一个线程i处于入口区，那么在i的请求被接收之前，其他线程进入临界区的时间是有限制的

**无忙等待（可选）**：如果一个进程在等待进入临界区，那么在它可以进入之前会被挂起

### 禁用硬件中断

没有中断，没有上下文切换，因此没有并发。

进入临界区，禁用中断

离开临界区，开启中断

缺点：

- 一旦中断被禁用，线程就无法被停止
  - 整个系统都会为你停下来
  - 可能导致其他线程处于饥饿状态
- 要是临界区可以任意长
  - 无法限制响应中断所需的时间（可能存在硬件影响）
- 要小心使用

- 多CPU下无法解决，因为只能关闭当前CPU的中断，其他CPU还是可以执行临界区

### 基于软件的解决办法

```c++
do{
    
}while(1);
```

共享变量：

```c++
int turn = 0;
turn == i //表示该谁进入临界区
Thread Ti
do{
    while(turn != i);  
    critical section
    turn = j;
    reminder section
}while(1);
```

满足互斥，但是有时不满足progress(前进)。即$T_i$做其他的事情，$T_j$想要继续运行，但是必须等待$T_i$处理临界区。

共享变量初始化：

```c++
int flag[2]; flag[0] = flag[1] = 0;
flag[i] == 1//指示进程是否准备好进入临界区

Thread Ti;
do{
    while(flag[j] == 1); //判断别的进程是否进入了临界区
   	flag[i] = 1;
    critical section;
    flag[i] = 0;
    remainder section
}while(1);
```

不满足互斥，开始时刻，flag[1]和flag[0]都为0，可以跳过while循环，从而将flag[0]和flag[1]都设为1，从而可以继续执行。

```c++
int flag[2]; flag[0] = flag[1] = 0;
flag[i] == 1//指示进程是否准备好进入临界区

Thread Ti;
do{
    flag[i] = 1;
    while(flag[j] == 1); //判断别的进程是否进入了临界区
    critical section;
    flag[i] = 0;
    remainder section
}while(1);
```

满足互斥，但是存在死锁。进程0将flag[0]设为1，然后切换到进程1，进程1将flag[1]设为1，此时两个进程都无法继续执行。

**正确的解法：**Deeker算法

使用两个共享的变量。

```c++
int turn;  //指示该谁进入临界区
bool flag[]; //指示进程是否准备好进入临界区
```

Code for ECTER_CRITICAL_SECTION

```c++
flag[i] = true;
turn = j;
while (flag[j] && turn == j);
```

Code for EXIT_CRITICAL_SECTION

```c++
flag[i] = false;
```

```c++
do{
    flag[i] = true;
	turn = j;
	while (flag[j] && turn == j);
    critical section
    flag[i] false;
    remainder section
}while(1);
```

针对两个进程，满足互斥，满足有限等待，满足progress。

针对n个进程的互斥操作的保护。

- Bakery算法：取号排队，如果两个窗口取号，号码相等时，根据进程ID进行排序。
- Eisenberg and McGuire算法

### 更高级的抽象

硬体提供了一些原语

- 想中断禁用、原子操作指令

操作系统提高了更高级的编程抽象来简化并行编程：

- 锁，信号量
- 从硬件原语中构建

锁是一个抽象的数据结构：

- 一个二进制状态：锁定/解锁
- Lock::Acquire()：获取锁
- Lock::Release()：释放锁

**原子操作指令：**

Test-and-set指令：测试和置位，完成3个指令

- 从内存中读取值
- 测试该值是否为1，然后返回真或假
- 内存值设置为1

Exchange指令：交换

- 交换内存中的两个值

```c++
bool TestAndSet(bool * target)
{
    bool rv = *target;
    *target = true;
    return rv;
}

void Exchange(bool *a, bool *b)
{
    bool temp = *a;
    *a = *b;
    *b = temp;
}
```

虽然这两个指令，语义上由多个小的指令完成，但是它们被封装成了机器指令，在指令中间，不会产生中断和切换。

利用这两个指令，来设计进入和退出临界区的代码。

**利用test-and-set实现：**

```c++
class Lock{
    int value = 0;
};

//如果锁被释放，那么test-and-set读取0并将值设置为1 ->锁被设置为忙并且需要等待完成
//如果锁处于忙状态，那么test-and-set读取并将值设置为1->不改变锁的状态并且需要循环
Lock::Acquire(){
    while(test-and-set(value));
}

Lock::Release(){
    value = 0;
}
```

不仅支持两个进程，还支持多个进程。

可以改进的地方：

- 使用忙等待的锁

无忙等待

```c++
class Lock{
    int value = 0;
    WaitQueue q;
};

Lock::Acquire(){
    while(test-and-set(value)){
        add this TCB to wait queue q;
        schedule();
    }
}

Lock::Release(){
    value = 0;
    remove one thread t from q;
    wakeup(t);
}
```

**使用exchange的实现：**

```c++
int key;
int lock = 0;
do{
    key = 1;
    while (key == 1) exchage(lock, key);
    critical section;
    lock = 0;
    remainder section
}while(1);
```

也可以设计基于无忙等的锁。

缺点：

- 忙等待消耗处理器时间
- 当进程离开临界区并且多个进程在等待的时候可能导致饥饿
- 死锁
  - 如果一个低优先级的进程拥有临界区并且一个高优先级进程也需要，那么高优先级进程会获得处理器并等待临界区。

### 信号量

一个整型sem，两个原子操作：

- P()：sem减1，如果sem<0，等待，否则继续
- V()：sem加1，如果sem<=0，唤醒一个等待的P

Dijkstar提出的，V：是荷兰语增加，P是荷兰语的减少。

信号量是一个**有符号的整数**，信号量是**被保护**的变量。

P()能够阻塞，V()不会阻塞。

两种类型信号量：

- 二进制信号量：可以是0或1
- 一般/计数信号量：可取任何非负值

信号量可以用在2个方面：

- 互斥
- 条件同步

### 信号量使用

使用二进制信号量，可以代替锁：

```c++
mutex = new Semaphore(1);
mutex->P();
...
critical section
mutex->V();  
```

用二进制信号量实现调度约束：

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191104161206.png)

Thread A的P()之后的操作，需要先等待Thread B的V()操作执行后，才能执行。

**生产者和消费者模型**

- 一个或多个生产者产生数据将数写入缓存区中

- 单个消费者每次从缓存区中读取数据

- 在任何一个时间只有一个生产者或消费者可以访问缓冲区

正确性要求：

- 在任何一个时间只能一个线程操作缓存区（互斥）
- 当缓存区为空，消费者必须等待生产者（调度/同步约束）
- 当缓存区满，生产者必须等待消费者（调度/同步约束）

互斥机制和同步机制：

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191104160210.png)

首先，初始化信号量，一个mutex互斥信号量，初始化为1；缓存区满信号量fullBuffers，初始化为0，表示一开始缓存区为空；缓存区为空信号量emptyBuffers，初始化在为n。

生产者Deposit()，消费者Remove()。

通过互斥信号量mutex来保证互斥。将Add c to the buffer包括起来，保证只能有一个线程操作buffer。

如果buffer没有满，可以继续执行，执行emptyBuffers的P操作，将emptybuffers减1，还是大于0，继续执行，最后执行fullBuffers的V操作，将fullBuffers加1，通知消费者执行。

消费者，首先执行fullBuffers的P()操作。对于首先生产者执行，因为末尾执行了fullBuffers的V操作，所以对于消费者可以继续执行。如果首先消费者执行，fullBuffers初始值为0，先执行减1，消费者进程进入等待，直到生产者进程执行fullBuffers的V操作，将fullBuffers变成0，消费者进程继续执行。

消费者最后执行emptyBuffers的V操作，是的emptyBuffers加1，使得睡眠在emptyBuffers->P()处的进程继续执行。

**注意：**P的操作顺序不能变，否则会产生死锁。V的操作顺序可以变，因为V没有进行阻塞操作。

可以尝试交换生产者的empytBuffers->P()和mutex->P()操作试试？

### 信号量的实现

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191106204603.png)

信号量的双用途：

- 互斥和条件同步
- 但等待条件是独立的互斥

### 管程

目的：分离互斥和条件同步的关注

管程提出用在编程语言层面的，简化语言进行同步互斥的操作。

管程(monitor)：包含一系列共享变量，以及针对这些变量操作的函数的模块。

- 一个锁：执行临界区
- 0或多个条件变量：等待/通知信号量用于管理并发访问共享数据

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191106205334.png)

Lock:

- Lock::Acquire()：等待直到锁可用，然后抢占锁
- Lock::Release()：释放锁，唤醒等待着如果有

Condition Variable

- 允许等待状态进入临界区
- Wait()操作：释放锁，睡眠，重新获得锁返回后
- Singnal()操作：唤醒等待者（或者所有等待者）

条件变量实现：

- 需要维护每个条件队列
- 线程等待的条件等待singal()

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191106205811.png)

使用管程解决生产者消费者问题：

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191106211051.png)

当执行Signal()，是当前正在执行的进程继续执行，还是让唤醒的进程执行？即下面的两种方式：Hoare和Hansen。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191106211638.png)

Hoare实现起来比较困难，而Hansen实现起来比较容易，操作系统和语言就是采用该方法。

这两种方式对我们管程中条件变量的使用也会产生影响。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191106211822.png)

总结：

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191106212416.png)

### 经典同步问题

#### 读者-写者问题

读者：不需要修改数据

写者：读取和修改操作

问题的约束：

- 允许同一时间有多个读者，但在任何时候只有一个写者
- 当没有写者时，读者才能访问数据
- 当没有读者和写着时，写者才能访问数据
- 在任何时候只能有一个线程可以操作共享变量

**读者优先**：如果有读者在读数据，并且有写者在等待，这个时候来了一个读者，读者可以跳过等待的写着，当当前读者读完，刚来的读者可以继续读。

共享数据：

- 数据集
- 信号量CountMutex初始化为1，保证只有一个读者读取数据
- 信号量WriteMutex初始化为1，保证只有一个写着写数据
- 整数Rcount初始化为0初始化为0，当前有多少个读者

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191107110330.png)

**写者优先**：一旦写着就绪，那么写着会尽可能第执行写操作。如果写着源源不断地出现，那么读者就始终处于阻塞状态。

当当前有写者正在执行，或者当前读者等待队列不为空，读者都需要等待。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191107111005.png)

对于读者：

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191107111808.png)

对于写者：

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191107121302.png)

broadcast()唤醒条件变量队列中的所有进程。

#### 哲学家就餐问题

问题描述：5个哲学家围绕一张圆桌而坐，桌子上放着5支叉子，每两个哲学家之间放一支；哲学家的动作包括思考和进餐，进餐时需要同时拿起他左边和右边的两只叉子，思考时则同时将两支叉子返回原处。如果保证哲学家们的动作有序进行？如：不出现有人永远拿不到叉子。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191108143447.png)

```c++
#define N 5                 //哲学家个数
void philosopher(int i)     //i哲学家编号
{
    while(1)
    { 
        think();            //哲学家思考
        take_fork(i);       //去拿左边的叉子
        take_fork((i+1)%N); //去拿右边的叉子
        eat();              //吃饭
        put_fork(i);        //放下左边的叉子
        put_fork((i+1)%N);  //放下右边的叉子
    }
}
```

上面方法会出现死锁。5个进程同时处理，第一步5个人都在思考，第二步，5个人同时拿左边的叉子。到第三步的时候，5个哲学家都无法拿到右边的叉子，并且无法释放左边的叉子，从而导致死锁。

```c++
#define N 5                 //哲学家个数
void philosopher(int i)     //i哲学家编号
{
    think();            //哲学家思考
    while(1)                //去拿两把叉子
    {
        take_fork(i);       //去拿左边的叉子
        if (fork(i+1)%N){       //右边叉子还在吗？
            take_fork((i+1)%N); //去拿右边的叉子
            break;
        }else{                  //右边叉子不在了
            put_fork(i);        //放下左边的叉子
            wait_some_time();    //等一会
        } 
    }
}
```

对拿叉子的过程进行了改进，但仍不正确。首先，5个进程同时开始执行，同时拿到左边的叉子，然后执行else里面的操作，放回叉子，等待相同的时间，继续去拿左边的叉子，出现了死循环。

```c++
#define N 5                 //哲学家个数
void philosopher(int i)     //i哲学家编号
{
    think();            //哲学家思考
    while(1)                //去拿两把叉子
    {
        take_fork(i);       //去拿左边的叉子
        if (fork(i+1)%N){       //右边叉子还在吗？
            take_fork((i+1)%N); //去拿右边的叉子
            break;
        }else{                  //右边叉子不在了
            put_fork(i);        //放下左边的叉子
            wait_random_time();    //等待随机长时间
        } 
    }
}
```

等待时间随机变化。可行，但非万全之策。

```c++
semaphore mutex;
void philosopher(int i)     //i哲学家编号
{
    while(1)
    { 
        think();            //哲学家思考
        P(mutex);
            take_fork(i);       //去拿左边的叉子
            take_fork((i+1)%N); //去拿右边的叉子
            eat();              //吃饭
            put_fork(i);        //放下左边的叉子
            put_fork((i+1)%N);  //放下右边的叉子
        V(mutex);
    }
}
```

互斥访问。方案正确。但是每次只允许一个人进餐。效率太低。把就餐堪称必须互斥访问的临界资源，因此会造成资源的浪费。

从理论上来说，如果有5把叉子，应该允许不相邻的哲学家同时进餐。

改进思路：

- S1: 思考中...

- S2：进入饥饿状态
- S3：如果左邻居和右邻居正在进餐，进程进入阻塞状态，否则转S4
- S4：拿起两把叉子
- S5：吃面条
- S6：放下左边的叉子，看看左邻居现在能否进餐（饥饿状态，两把叉子都在），若能则唤醒之
- S7：放下右边的叉子，看看右邻居现在能否进餐（饥饿状态，两把叉子都在），若能则唤醒之
- 新的一天又开始了，转S1



```c++
#define N 5                 //哲学家个数
#define LEFT i              //第i个哲学家的左邻剧
#define RIGHT (i+1)%N       //第i个哲学家的右邻居
#define THINKING 0          //思考状态
#define HUNGRY 1            //饥饿状态
#define EATING 2            //进餐状态
int state[N];               //记录每个人的状态

//该状态是一个临界资源，对它的访问应该互斥地进行
semaphore mutex;            //互斥信号量，初值为1

//一个哲学家吃饱后，可能要唤醒邻居，存在同步关系
semaphore s[N];             //同步信号量，初值为0

void philosopher(int i)
{
    while(true)
    {
        think();           //对应S1,思考中
        take_forks(i);     //对应S2-S4,拿到两把叉子或被阻塞
        eat();             //对应S5，吃面条中，不需要任何设计
        put_forks();       //对应S7-S8，把两把叉子放回原处
    }
}

//功能：要么拿起两把叉子，要么被阻塞起来
void tate_fork(int i)
{
    P(mutex);           //进入临界区，因为别的进程需要读取state[i]，来判断旁边的哲学家释放在进餐
    state[i] = HUNGRY;  //饥饿状态
    test_take_left_right_forks(i);  //试图拿起两把叉子
    V(mutex);           //退出临界区
    P(s[i]]);           //没有叉子阻塞，由于test_take_left_right_forks(i)中的V(s[i])进行了加1，所以不会阻塞
}

void test_take_left_right_forks(int i)
{
    //我在饥饿状态，左邻剧和右邻居没有处于进餐状态
    if (state[i] == HUNGRY && state[LEFT] != EATING && state[RIGHT] != EATING)
    {
        state[i] = EATING:       //两把叉子到手
        V(s[i]);                 //通知第i人可以吃饭了，将s[i]加1，使得后面的P(s[i])不被阻塞
    }
}

//功能：把两把叉子返回原处，并在需要的时候去唤醒左邻居和右邻居
void put_forks(int i)
{
    P(mutex);                                //进入临界区，因为牵涉state[i]的赋值，所以要互斥保护
    state[i] = THINKING;                     //交出两把叉子
    test_take_left_right_forks(LEFT);        //看左邻剧能否进餐
    test_take_left_right_forks(RIGHT);       //看右邻居能否进餐                  
    V(mutex);                                //退出临界区
}

void think()
{
    P(mutex);             //进入临界区，因为牵涉state[i]的赋值，所以要互斥保护
    state[i] = THINKING:  //设为思考状态
    V(mutex);             //退出临界区
}
```

### 死锁

一组阻塞的进程持有一种资源等待获取另一个进程所占用的一个资源。由于并发执行导致，共享资源所有进程都可以去占用，而且资源是互斥的。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191110094103.png)

如果图中不包含循环，没有死锁。

如果图中包含循环，如果每个资源类只有一个实例，那么没有死锁。

如果每个资源类有几个实例，可能死锁。

#### 死锁特征

四个条件同时成立：

- **互斥**：在一个时间段内只能有一个进程使用资源
- **持有并等待**：进程保持至少一个资源正在等待获取其他进程持有的额外资源
- **无抢占**：一个资源只能被进程资源释放，进程已经完成了他的任务之后
- **循环等待**：存在等待进程集合${P_0, P_1,...,P_N}$，$P_0$正在等待$P_1$所占用的资源，$P_1$等待$P_2$占用的资源，...，$P_{N-1}$等待$P_N$占用的资源，$P_N$等待$P_0$所占用的资源。

死锁的四个必要条件。一旦有了死锁，这四个条件不成立，但是这四个条件成立，不一定会产生死锁。

#### 死锁处理办法

- 确保系统永远不进入死锁状态
- 运行系统进入死锁状态，然后恢复
- 忽略这个问题，假装系统中从来没有发生死锁；用于大多数操作系统，包括UNIX。

**死锁预防**：

打破死锁的4个必要条件之一：

- 互斥：共享资源不是必须的，必须占用非共享资源，即将互斥资源并称非互斥资源，这个不太好。
- 持有并等待：必须保证当一个进程请求的资源，它不持有任何其他资源。所有资源都能拿到就继续执行，否则拿不到就睡眠。会导致资源利用率低，可能发生饥饿。

- 无抢占：如果进程占有某些资源，并请求其他不能被立即分配的资源，则释放当前正占用的资源。

- 循环等待：对所有资源类型进程排序，并要求每个进程按照资源的顺序进行申请。多用于嵌入式系统，资源类型有限。

**死锁避免**：

当进程申请资源时，判断申请的资源是否合理，即是否会产生死锁。

- 每个进程声明它可能需要的每个类型资源的最大数目
- 资源的分配状态是通过限定提供和分配的资源数量，和进程的最大需求

- 死锁避免算法动态检查的资源分配状态，以确保永远不会有一个环形等待状态

**死锁检测**：

死锁检测允许系统进入死锁状态，如果检测到系统进入死锁状态，再进行恢复。

- Available(剩余空闲量)：长度为m的向量。如果$Available[j]=k$，表示有$k$个类型$R_j$的资源实例可用。
- Allocation(已分配量)：n×m矩阵，，如果$Allocation[i,j]=k$，表示进程$P_i$当前分配了$R_j$的$k$个实例
- Request：一个n×m矩阵表示各进程的当前请求。如果$Request[i,j]=k$，表示进程$P_i$请求$k$个资源$R_j$的实例

死锁检测算法：

```c++
//1. Work和Finish分别是长度为m与n的向量
Work = Available;          //Work当前空闲资源
for i = 1, 2...n
    if Allocation[i] > 0
		Finish[i] = false; //Finish为线程是否可结束
	else
        Finish[i] = true;

//2. 找出这样的索引
Finish[i] = false;        //找到没有结束的进程，且此线程将需要的资源量小于当前空闲资源量
Request[i] <= Work;
没找到这样的i，转到第4步
    
//3. 执行进程，释放资源
Work = Work + Allocation[i]; //把找到的线程拥有的资源释放回当前空闲资源中
Finish[i] = true;             //表示进程i可以结束

//4. 检测是否死锁
for some i, 1 <= i <= n          //如果有Finish[i]等于false，这表示系统处于死锁状态
	if Finish[i] = false    
        系统处于死锁状态
        P[i]死锁
```

基于以下两个原因：

- 开销比较大

- 需要获取每个进程需要的最大资源数量很困难

银行家算法和死锁检测算法在系统中基本不会使用，一般来用检测。

**死锁恢复**：

- 终止所有的死锁进程
- 在一个时间内终止一个进程知道死锁消除
- 终止进程的顺序应该是：
  - 进程的优先级
  - 进程运行了多久以及需要多少时间才能完成
  - 进程占用的资源
  - 进程完成需要的资源
  - 多少进程需要被终止
  - 进程是交互还是批处理

#### 银行家算法

银行家算法是一个死锁避免的著名算法。

银行家算法的前提：

- 多个实例
- 每个进程都必须能最大限度地利用资源
- 当一个进程请求一个资源，就不得不等待
- 当一个进程获得所有的资源就必须在一段有限的时间释放它们

基于上述前提条件，银行家算法通过尝试寻找允许每个进程获得的最大资源并结束的进程请求的一个理想执行时序，来决定一个状态是否是安全的。

不存在满足要求的执行时序的状态都是不安全的。

银行家算法数据结构:

n=进程数量， m= 资源类型数量

- Max(总需求量)：n×m矩阵，如果$Max[i,j]=k$，表示进程$P_i$最多请求资源类型$R_j$的$k$个实例
- Available(剩余空闲量)：长度为m的向量。如果$Available[j]=k$，表示有$k$个类型$R_j$的资源实例可用。
- Allocation(已分配量)：n×m矩阵，，如果$Allocation[i,j]=k$，表示进程$P_i$当前分配了$R_j$的$k$个实例
- Need(未来需要量)：n×m矩阵，，如果$Need[i,j]=k$，表示进程$P_i$可能需要至少$R_j$的$k$个实例完成任务

$$
Need[i,j]=Max[i,j] - Allocation[i,j]
$$



第一步：$Work$和$Finish$分别是长度为m和n的向量。

初始化：

```c++
Work = Available;      //当前资源剩余空相良
Finsh[i] = false;      //进程i没结束，如果等于true，拥有了所有资源，可以执行并结束
```

第二步：找这样的$i$

```
Finish[i] = false;
Need[i,:] <= Work
```

没找到这样的$i$，转到第四步

第三步：

```c++
Work = Work + Allocation[i,:];    //进程i的资源需求量小于当前剩余空闲资源量，所以分配资源给他执行，执行完成再回收
Finish[i] = true;  

```

转到第二步

第四步：

```c++
if Fininsh[i] == true for all i  //所有进程的Finish为true，表示系统处于安全状态
    then the system is in a safe state
 else           //不安全状态 
     then the system is in a unsafe state
```

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191110171506.png)

​	



例子：一个得到safe序列的例子。

得到一个安全的执行序列：P2->P1->P3->P4

![](https://raw.githubusercontent.com/zxpgo/images/master/img/safe.png)

例子：找出得到一个不安全状态。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/unsafe.png)

首先分配给P1的资源为[1,0,1]，这样进入(b)阶段，可用资源变成了[0,1,1]，无法再满足现有进程的资源需求，这是一个不安全的状态。

### 进程间通信(IPC)

进程间通信可以分为间接通信(a)和直接通信(b):

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191111103036.png)

直接通信：

- 进程必须证明的命名对方：
  - send(P, message)，发送到进程P
  - reveive(Q, message)

间接通信：

- 定向从消息队列接收消息
  - 每个消息队列都有一个唯一ID
  - 只有它们共享了一个消息队列，进程才能通信
- 原语的定义
  - send(A, message)，发送到消息队列A
  - reveive(A, message)

消息传递可以是阻塞或非阻塞的：

- 阻塞认为是同步的：即发送一个消息后等待返回消息，接收方等待一个消息直到收到消息
- 非阻塞认为是异步的：即发送方发送完消息，继续执行不等待返回结果

通信链路缓冲：

- 0容量：不缓冲，发送一个消息给对方，对方等待直到收到消息
- 有限容量：发送方一直往长度为n的buffer中写入数据，直到buffer满了；而接受发当buffer不为空的时候从缓冲区中读数据。
- 无限容量：不需要等待，但是接收方当buffer为空时不得不等待，理论分析采用

#### 信号

软件中断通知事件处理，发出一些通知信息。

接收到信号是处理：

- Catch：指定信号处理函数被调用
- Ignore：依靠操作系统的默认操作
- Mask：阻塞信号因此不会传送，可能是暂时的

不足：不能传输要交互的任何数据，只能起到一种通知的作用。

首先，应用程序注册一个信号，发送给操作系统。

然后，操作系统内核收到信号，将另一个进程的堆栈信息中下一个执行入口切换为对应信号的函数。

最后，另一个应用程序开从信号对应的函数开始执行。

#### 管道

管道是进行数据交换的。

Linux中的管道符`|`，比如`ls | more`的执行过程如下图：

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191111105616.png)

管道其实就是内存中的一段缓冲区。

如果buffer满了，ls会被阻塞，但是当more消耗了buffer，就会唤醒ls进程。

shell的作用：

- 创建管道
- 为ls创建一个进程，设置stdout为管道写端
- 为more创建一个进程，设置stdin为管道读端

**管道必须有一个父进程。**管道里面的数据是一种字节流。

#### 消息队列

消息队列也是一种数据的传递机制。**管道通过父进程帮子进程建立好通道。**管道里面的数据是一种字节流。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191111110214.png)

消息队列传递是一个某种结构，两个不同的进程可以来传输数据。这样是个结构化数据结构，接收方不用进行解析。**同样缓冲区也是有限制的。**

#### 共享内存

管道和消息队列是一种间接的通信方式。而共享内存是一种直接通信方式。

- 每个进程都有私有地址空间
- 在每个地址空间内，明确地设置了共享内存段

优点：

- 快速，方便地共享数据

不足:

- 必须同步数据访问，采用同步互斥机制来保证

通过将同一块物理内存映射到不同的进程的相同或不同的地址空间，通过虚地址访问不同进程的共享内存的虚地址其实访问的是同一块物理内存空间。

#### socket

网络部分的内容。虽然TCP和UDP实现在内核态。

# 文件系统

## 基本概念

**文件系统**：一种用于持久性存储的系统抽象

**文件**：文件系统中一个单元的相关数据结构在操作系统中的抽象

文件系统的功能：

- 分配文件磁盘空间
  - 管理文件块（哪一块属于哪一个文件）
  - 管理空闲空间（哪一块是空闲的）
  - 分配算法（策略）
- 管理文件集合
  - 定位文件及其内容
  - 命名
  - 最常见：分层文件系统
- 提供便利及特征
  - 保护：分层来保护数据安全
  - 可靠性/持久性：保持文件的持久即使发送崩溃，攻击等

文件：

- 文件属性
  - 名称、类型、位置、大小、创建者、创建事件、最近修改事件
- 文件头
  - 存储元数据中保存了每个文件的信息
  - 保存文件的属性
  - 跟踪哪一块存储块属于逻辑上文件结构的哪个便宜

**文件描述符**：

使用程序必须在使用前“打开”文件：

```c++
f = open(name, flag);

...=read(f, ...);

...
close(f);
```

文件描述符是一个整数，所有打开的文件有一个表，叫做打开文件表，而文件描述符就是打开文件表的索引，当执行read或write操作时，根据索引(文件描述符)查找打开文件表得到相应的文件信息。

操作系统为每个进程维护一个打开文件表。

需要元数据来管理打开文件：

- 文件指针：指向最近的一次读写位置，每个打开了这个文件的进程都有这个指针
- 文件打开计数：记录文件打开的次数，当最后一个进程关闭了文件时，允许将其从打开文件表中移除
- 文件磁盘位置：缓存数据访问信息
- 访问权限：每个程序访问模式信息

操作系统内部视角：

- 块的集合（块时逻辑转换单元，而扇区是物理转换单元）
- 块大小 <> 扇区大小

多用户文件中的文件共享很必要的。

- 访问控制：
- 文件访问控制列表(ACL)
- Unix模式
  - 用户ID识别用户，表明每个用户所允许的权限及保护模式
  - 组ID允许用户组成组，并指定了组访问权限

**目录**：文件以目录的方式组织起来

目录是一类特殊的文件，每个目录包含了一张表。

目录的操作：

- 搜索文件
- 创建文件
- 删除文件
- 枚举文件
- 重命名
- ....

一个文件系统需要先挂载才能被访问。

一个未挂载的文件系统被挂载在挂载点上。

**文件别名**：

两个或多个文件名关联同一个文件。

硬链接：多个文件项指向一个文件，

软链接：以“快捷方式”指向其他文件，文件中存储的另一个文件的路径

通过存储真实文件的逻辑名称来实现。

如果删除一个有别名的文件会如何呢？

软链接：这个别名将成为一个“悬空指针”。

硬链接：文件块信息中有一个别名计数，只有当所有硬链接被删除了，才会删除文件

引入链接机制，如何保证没有循环？

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191111153514.png)

- 通过循环检测算法
- 限制路径可遍历文件目录的数量

**文件系统种类**：

- 磁盘文件系统：

  文件存储在存储设备上，如磁盘

  FAT、NTFS、ext2/3，ISO9660

- 数据库文件系统：

  文件根据其特征可被寻址的

  例如WinFs

- 日志文件系统

  记录文件系统的修改/事件

- 网络/分布式文件系统

  NFS、SMB、AFS、GFS

- 特殊/虚拟文件系统

  不是为了存储数据，而是给读和写一种接口

## 虚拟文件系统

分层结构：

- 上层：虚拟文件系统
- 底层：特定文件系统模块

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191112092911.png)

目的：对所有不同文件系统的抽象

功能：

- 提供相同的文件和文件系统接口
- 高效查询例程，遍历文件系统
- 与特定文件系统模块的交互

卷控制块：(Unix: "Superblock")

- 每个文件系统有一个
- 文件系统详细信息
- 块，块大小，空闲块，计数/指针等

文件控制块：（Unix: "vnode"or"inode"）

- 每个文件一个
- 文件详细信息
- 许可，拥有者，大小，数据库位置等

目录结点（Linux：“dentry”）

- 每个目录项一个（目录和文件）
- 将目录项数据结构及树型布局编码成树型数据结构
- 指向文件控制块，父节点，项目列表等

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191112093431.png)

文件系统数据结构：

- 卷控制块
- 文件控制块
- 目录结点

当需要时加进内存：

- 卷控制模块：当文件系统挂载时进入内存
- 文件控制块：当文件被访问时进入内存
- 目录结点：在遍历一个文件路径时进入内存

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191112093704.png)

## 数据缓冲

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191112093928.png

基于页的缓冲，方便应用程序读取。

## 打开文件的数据结构

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191112095442.png)

根据打开文件表中的文件信息，找到文件在磁盘中的扇区，然后读取扇区中的数据。

## 文件分配

分配方式：

- 连续分配
- 链式分配
- 索引分配

**连续分配：**

分配策略：最先匹配、最佳匹配、最差匹配

优势：文件读取表现好，高效的顺序和随机访问

缺点：碎片，文件增长问题

**链式分配**

文件以数据块链表方式存储

优点：创建、增大、缩小很容易；没有碎片

缺点：不可能进行真正的随机访问，可靠性

**索引分配**

为每个文件创建一个名为索引数据块的非数据数据块

优点: 创建、增大、缩小容易；没有碎片；支持直接访问

缺点：当文件很小时，存储索引的开销；索引块大小有限，如果存储大文件呢？

对于大文件的解决方案：

链式索引块和多级索引块：

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191112101137.png)

多级索引块和多级页表有相同之处。

Unix早期三级文件索引：

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191112101335.png)

## 空间空间列表

用位图代表空闲数据块列表：

11111110000001111111111000101

如果$i=0$表明数据块$i$是空闲的，反之则已分配。

位图存储在磁盘中，需要读取到内存中来。需要确保两者的一致性。解决方案：

- 现在磁盘上设置对应的位bit[i]=1
- 分配block[i]
- 在内存中设置bit[i]=1

即使在磁盘中设置bit[i]=1，然后掉电了没有将数据写入，也不会有数据丢失的情况。

链式列表和分组列表：

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191112102213.png)

## 多磁盘管理-RAID

磁盘是一个机械设备。下面是基本的原理图：

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191112102405.png)

分区：硬件磁盘的一种适合操作系统指定格式的划分

卷：一个拥有一个文件系统实例的可访问的存储空间

RAID:冗余磁盘阵列

不同RAID分类：RAID-0,RAID-1,RAID-5

**RAID0:**

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191112105956.png)

提高了访问速度。数据存储到不同的盘，提高访问速度。

**RAID1:**

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191112110015.png)

提高了可靠性。存储一个相同的备份。

**RAID4:**

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191112105646.png)

添加一个额外的盘来支持容错，但是只能在一个盘坏了的情况下才能恢复。结合了RAID-0和RAID-1的特性。往Disk i写数据时，Parity Disk也要进行写数据，这样Parity Disk写数据变成了瓶颈。

**RAID-5:**

将RAID-4中Parity Disk的开销分到每个Disk中，就得到了RAID-5。

![](https://raw.githubusercontent.com/zxpgo/images/master/img/20191112105812.png)

校验的开销是均匀的。保证了高可靠性，但是只能矫正一个磁盘的错误。

需要矫正两个盘的错误，需要采用RAID-6等。

RAID-0/4/5：基于快级别的校验

RAID-3：基于bit级别的校验

RAID-5是最常用的。

## 磁盘调度

磁盘可以有多个盘片，每个盘片有一个或两个磁头，（两个磁头对应正反面）。

磁头的旋转和前后移动，都是机械操作，速度非常慢。

**寻道时间：**定位到期望的磁道所花费的时间

**旋转延迟：**从扇区的开始处到达目的处花费的时间

平均旋转延迟时间=磁盘转换一周时间的一半

访问时间：

寻道时间的开销是最大的。

**先进先出：**

应用程序访问的磁盘的按照先来先处理的原则。

**最短服务优先**：

会出现饥饿现象。

**SCAN方法：**

磁盘在一个方向移动，满足所有为完成的请求，直到磁盘到达该方向上最后的磁道。

**C-SCAN：**限制了仅在一个方向上扫面。到达最后的磁道，直接跳到最前面的磁道重新开始扫描。

**C-SCAN改进：**磁臂先到达该方向上最后**最后一个请求处**，然后立即反转。

**N-Step-SCAN算法：**将磁盘请求队列分成若干个长度为N的子队列，磁盘调用将按FCFS算法依次处理这些子队列。而每处理一个队列时又是按SCAN算法，对一个队列处理完后，再处理其他队列。

