---

title:  操作系统
date: 2019-04-21 13:44:14
tags: C++
mathjax: true

---

多进程视图和文件视图，包括进程管理、内存管理、IO设备和磁盘管理。<!--more-->

## 操作系统介绍


boot ： 取值执行

	bootsect.s（汇编）
	
		从磁盘将操作系统读取到内存中，操作系统的引导扇区完成该项工作。boosect.s从操作系统的代码读取到内存中，并打印开机画面。并将操作系统后面的，system读入。
	
	setup.s(汇编)
	
		初始化，知道硬件的信息。
	
		读取光标位置
		
		读取内存大小，方便管理内存
		
		读取显卡参数
		
		移动到0地址处，执行系统
	
	
	system模块
	
		head.s是system的第一个文件
		
		Makefile: 编写Makefile来对程序进行编译
		
		head.s初始化GDT表，进入main函数



多进程视图：
	
	CPU管理
	
	内存管理

文件视图：

	IO设备
	
	磁盘文件

	

## CPU管理

如何使用CPU

__CPU工作原理：（取址执行）__

程序存放在内存中，CPU设置一个PC指针，CPU根据PC指针通过总线发送取指令给内存，内存将PC指针处的指令通过总线传送给CPU。

CPU得到指令，解释执行指令。

CPU不断的取址执行。PC指针不断递增。


PC设置一个初始值，CPU就不断取址执行，一直工作。

管理CPU的最直观的方法：设置好一个PC初值

如果执行计算指令，等待I/O，再执行下面的指令。这样，CPU利用率非常低，接近0。注意：I/O消耗的时间是一条计算指令的10^6倍。

解决办法：当执行不下去的时候，切换执行其他程序继续去执行。这样，就会来回切换来切换去，CPU的利用率就高了。

__多道程序、交替执行__提供了CPU利用率。


一个CPU上交替的执行多个程序：__并发__

怎么做到并发： 切换寄存器PC指针，还需要记录切换出去之前的程序的信息。

运行的程序和静态程序不一样！

引入“进程”概念，描述运行中的程序！

- 进程有开始、结束，程序没有
- 进程会停止和继续，程序没有
- 进程需要记录程序运行的信息，而程序不要


CPU管理和运行多个进程，交替执行多个进程。

### 操作系统如何支持多进程

多个进程如何使用CPU

- 如何使用CPU: 让程序执行起来

- 如何充分利用CPU: 启动多个程序，交替执行

- 启动了的程序就是进程，所以是多个进程推进： 操作系统只需要把这些进程记录好、要按照合理的次序推荐（分配资源、进行调度）


多进程图像从启动开始到关机结束：

- main中的fork()创建了第一个进程： init执行了shell

- shell再启动其他程序： 在shell输入一个命令，再创建一个进程



启动计算机，就是启动一堆进程。管理计算机，就是管理一堆进程。

### 多进程如何组织

Process Control Block(PCB): 用来记录进程信息的数据结构

有一个进程在执行，有一些进行等待执行，有一些进程在等待某事件。

#### 多进程的组织： PCB+状态+队列

![](https://i.imgur.com/yfHabC7.png)

操作系统根据状态图让进行进程的转换。

阻塞态：等待某事件是，转换为阻塞态。


#### 多进程的交替

例子：

	启动磁盘读写
	
	切换为阻塞态
	
	加入阻塞等待队列
	
	schedule()《重点》

	
	schedule()
	{
		pNew = getNext(ReadyQueue);  //调度： 从等待队列中找出下一个进程
		switch_to(pCur, PNew);
	}
	//pCur、PNew是PCB



#### 交替的三个部分: 队列操作+调度+切换

进程调度算法： FIFO(先进先出)、Priority(设置优先级)

切换： switch_to(pCur, pNew)

#### 多进程如何影响

多个进程同时存在于内存会导致访问同一个地址，并对其修改。

解决办法：限制对地址的读写

多进程的地址空间分离：内存管理的主要内容

基本思想：映射表

每个进程有自己的映射表，进程使用虚拟内存，然后通过映射表查找出物理内存。


![](https://i.imgur.com/8Jt6rSz.png)



#### 多进程如何合作

打印过程：

- 应用程序提交打印任务

- 打印任务被放进打印队列

- 打印进程从队列中取出任务

- 打印进程控制打印机打印

生产者-消耗者模型： 有进程往共享缓冲区存入内容（生产者），有进程从共享缓冲区读取内容（消费者）。

进程同步： 

![](https://i.imgur.com/yqTjwYP.png)

### 用户级线程

线程： 只有指令切换，资源不变，多个线程共享资源。速度变快。保留了并发的特点，避免了进程切换代价。

核心是： Yield, 用户自动释放

Create就是制造出第一次切换时应该的样子。

每个线程都有一个栈和TCB。切换线程时，需要切换TCB和栈。

![](https://i.imgur.com/SdZxSYI.png)

### 内核级线程

如果进程的某个线程进入内核并阻塞了，导致切换到其他进程。

比如，发起URL请求，等待网卡IO，会导致进程阻塞，直接切换到其他进程，这时浏览器还是一堆空白。

内核中阻塞，线程的并发将无效果。

而内核级线程，在内核中阻塞了，可以切换到其他线程，并发性更好。

核心： Schedule，内核调度

![](https://i.imgur.com/gvPraOw.png)

多处理器：

多核： 只有支持核心级线程，才有作用

MMU: 内存映射， 用一个内存映射，就是使用相同的地址，即线程

![](https://i.imgur.com/4rsvT7n.png)

并发： 同时出发，交替执行

并行： 同时执行

多核有操作系统管理，用户级线程无法给其分配硬件。所以核心级线程才有意义。


TreadCreate是系统调用，内核管理TCB，内核负责切换线程。

两套栈：既要在用户态跑，也不要在内核跑，所以需要两套栈（用户栈和内核栈），一个TCB关联一套栈，切换的时候，根据TCB切换一套栈。

用户级线程： 两个栈关联两个TCB（用户栈）。切换的时候，根据TCB切换一个栈。

![](https://i.imgur.com/3jg517H.png)

所有中断（实战、外设、INT指令）都引起上述切换。

INT指令中断，就启用内核栈。

源SS、源SP： 用户态运行的栈

源PC、源CS： 用户态运行到的指令，即用户态程序执行的地址

IRET: 根据内核栈找到用户态执行的地方

![](https://i.imgur.com/TvSwOVR.png)

????:包含iret的代码，返回到用户态

??: 线程用户态的代码

???: 中断处

一个线程从用户态到内核态，根据TCB切换内核栈，找到切换后的内核态，并关联到对应的用户态。

通过中断进入内核态， irect返回到用户态。

![](https://i.imgur.com/Yl3mRmF.png)

五段论： 线程1用户栈 -> 线程1内核栈 -> 线程1TCB切换到线程2TCB -> 线程2内核栈 -> 线程2用户栈

创建线程：

![](https://i.imgur.com/JZogUws.png)

用户级线程和核心级线程的对比：

![](https://i.imgur.com/4DigsI6.png)

### 内核级线程实现

__五段论__： 线程1用户栈 -> 线程1内核栈 -> 线程1TCB切换到线程2TCB -> 线程2内核栈 -> 线程2用户栈

![](https://i.imgur.com/qfvzXCG.png)

fork()是系统调用，会引起中断。fork()是创建进程的系统的调用。fork() 转换为： INT 0X80

ThreadCreate

copy_process的细节： 创建栈

get_ free _page()内核代码，申请内存

malloc: 是用户态代码

创建核心级线程：

	创建TCB

	创建内核 栈和用户栈

	关联栈和TCB

## CPU调度策略

调度算法的设计目标：

- 尽快结束任务：周转时间（从任务进入到任务结束）短
- 用户操作尽快响应： 响应时间（从操作发送到响应）短
- 系统内耗时间少： 吞吐量（完成的任务量）

吞吐量和响应时间之间的矛盾： 响应时间小 -> 切换次数多 -> 系统内耗大 -> 吞吐量小

前台任务和后台任务的关注点不同： 前台任务关注响应时间； 后台任务关注周转时间

IO约束型任务（写磁盘的次数多）和CPU约束型任务（长时间没有磁盘读写）有各自的特点。

IO约束型任务大多是前台任务，其优先级应该高一些，这样能提高IO和CPU的并行。

__调度需要折中和综合，使得操作系统变得复杂。调度算法应该非常简单，不然调度算法没有价值。__


### 各种CPU调度算法 

#### SJF: 短作业优先 

FCFS： 先来先服务

![](https://i.imgur.com/jHjngyT.png)

FCFS太简单

考虑短作业优先，这样周转时间会最短。具体分析如下图：

![](https://i.imgur.com/0WndMNt.png)

SJF的周转时间最短。

此时没法保证响应时间。

#### RR: 按时间来轮转调度（Round Robin） 

时间片大：响应时间太长；时间片小吞吐量小
![](https://i.imgur.com/CltcdzI.png)

折衷： 时间片10~100ms，切换时间0.1~1ms(1%)

####  Priority: 优先级

word很关心响应时间，而gcc更关心周转时间，两类任务同时存在怎么办？

直观想法：定义前台任务和后台任务两个队列，前台RR，后台SJF，只有前台任务没有时才调度后台任务。

![](https://i.imgur.com/K06PKHk.png)

如果前台任务绝对优先，这样会导致后台任务可能一直无法执行。

显然这样是不合适的，因此后台任务优先级动态升高，但后台任务一旦执行，前台的响应时间就没有处理。

前后台任务都用时间片，但又退化为了RR，后台任务的SJF如何体现？前台任务如何照顾？

这样会导致折衷非常复杂。

其他问题：

- 无法知道是前台任务还是后台任务?通过学习机制，认识任务
- gcc如果交互，算前台任务还是后台任务？

#### 一个实际的schedule函数


![](https://i.imgur.com/LRqeZ5m.png)

counter有两个作用：

- 时间片
- 优先级

![](https://i.imgur.com/qlievWm.png)

### 进程同步与信号量

进程合作：多进程共同完成一个任务

多个进程合理有序地向前推进，同步可以实现多个进程合理有序运行，而信号是多个进程之间通信，即告诉进程可以继续执行。

等待是进程同步的核心。

生产者-消费者实例就是一个多进程同步的例子。

![](https://i.imgur.com/V6p1y9A.png)

生成者进程中当`counter==BUFFER_SIZE` 表示缓冲区已满，此时无法再往里面添加数据。而当销毁者进程执行，消耗缓冲区，这是发送信号给生产者进程，可以继续执行往缓冲区添加数据。具体如下图：

![](https://i.imgur.com/t1zMAek.png)

依靠counter来进行语义判断，无法解决问题：

还需要知道有多少个睡眠生产者进程在等待。仅仅发一个信号不够，还需要另一个量来判断是否要发送信号，而不是根据counter。

![](https://i.imgur.com/ATzETbG.png)

引入信号量，解决睡眠生产者进程等待问题：

![](https://i.imgur.com/uhqmbtj.png)

信号量sem的具体工作原理：

![](https://i.imgur.com/yH0RgXo.png)BTK.png)

sem=-1表示有一个睡眠生产者进程在等待；sem=1时表示还有一个空闲缓冲区，接下来的生产者进程进来可以直接执行。

根据信号量来表示等待和唤醒。生产者：信号量为负表示睡眠等待；消费者：信号量为负表示唤醒生产者进程。

__信号量的定义以及函数调用：__
![](https://i.imgur.com/TTG5Ktz.png)

生产者进程进入时，执行P(sem)，value减1，如果value小于零，表示缓冲区已满，这该进程睡眠等待。

消费者进程消耗资源时，执行V(sem)，V的代码如下：
	
	V(semaphore s)
	{
		s.value++;	
		if(s.value <= 0)
			wakeup(s.queue);
	}

信号量解决生产者-消费者问题：

![](https://i.imgur.com/GiT7Vwn.png)

empty表示信号量，即空闲的缓冲区数量，负数表示缓冲区已满，并且有多少个进程在等待。P(empty)empty减1，并判断是否缓冲区已满；V(empty)empty加1，并判断是否有等待生产者进程。

full表示缓冲区中内容数量。P(full),消费者判断缓冲区中是否有内容，如果有则执行，否则阻塞。V(full)，生产者增加缓冲区中的内容。

往文件中写内容，只能有一个进程在读写文件，因此定义了一个互斥信号量muter，表示一次只有一个进程进行文件读写。P(mutex)判断是否为1，如果为1，进行文件读写，并将mutex置为0。V(mutex)表示将mutex重新置为1。只有重新置为1了，其他进程才能进行文件读写。

#### 信号量临界区保护

多个进程共同修改信号量可能引发的问题：

![](https://i.imgur.com/rwNMpNG.png)

![](https://i.imgur.com/lgClgzY.png)
解决竞争条件的直观想法：

![](https://i.imgur.com/jhyZs97.png)

临界区（Critical Section）：

![](https://i.imgur.com/69fCgcf.png)

#### 三种解决方法

临界区代码的保护原则：

![](https://i.imgur.com/IJLUhpy.png)

__轮换法__

![](https://i.imgur.com/zpNCNa3.png)

无法满足有限等待。轮换法类似于值日。

__标记法__


![](https://i.imgur.com/ENPR0UV.png)

每个想进入临界区的进程都打一个标记，然后判断另一个进程是否标记，如果另一个进程进行了标记，那么该进程就等待，直到另一个进程撤销掉标记。

满足互斥进入要求，但是无法满足有空进入。

![](https://i.imgur.com/jsJybOg.png)

__非对称标记__

__Peterson算法__

![](https://i.imgur.com/frghLxn.png)

Peterson算法正确性：

![](https://i.imgur.com/f3MmfNo.png)


__1. 面包算法__

以上算法针对两个进程时，如果多个进程时，采用面包店算法。

![](https://i.imgur.com/hfl2524.png)

面包算法正确性分析：

![](https://i.imgur.com/f6d1PTm.png)

面包算法太复杂，以上都是软件实现。如果考虑采用硬件实现，将变得简单。

__2. 硬件上关闭中断__

通过关闭时间中断来阻止调度。不进行调度，就不会切换到别的进程。

![](https://i.imgur.com/9T1bb6f.png)

多CPU时，无法控制别的CPU的时间中断。

__3. 硬件原子指令法__

通过设计一个原子指令(即一次执行完成)来保证修改一个整型变量时，一次完成该变量的修改，而不会切换到别的进程。

![](https://i.imgur.com/qmSjvHu.png)

上图右侧代码，一次执行完成，而不会在中途切换到其他进程。

__用临界区保护信号量，用信号量实现多进程同步。__


#### 信号量代码实现

左边是伪代码，右边为实际程序。

![](https://i.imgur.com/8bSonLf.png)

信号量需要多个进程可见，所以信号量存储在内核中。（1）首先申请信号量，此时进入内核，调用sem.c程序；(2)生产者代码，向文件写入内容，在写之前需要判断是否有空闲缓冲区，通过调用sem_waite()。采用开关中断cli()、 sti()保护共享的值，比如value和队列。


Linux内部读磁盘时，需要使用信号量来保证多进程同步。

![](https://i.imgur.com/s2lvceA.png)

bread()读磁盘，首先申请一块空闲缓冲区，然后，启动读的命令，启动后就进行阻塞。缓冲区带有一个信号量b_ lock，b_ lock=1表示上锁，一旦上锁表示有进程在读写当前缓冲区，后面进来的进程都进入睡眠。通过中断来进行解锁。通过开关终端cli和sti来保护临界区。

sleep_on()中阻塞队列的形成方式:

![](https://i.imgur.com/ytd0K5d.png)

tep局部变量存放在当前进程的内核栈，task_ struct能够找到tmp，切换栈的时候temp也能切换。根据task_ struct能够找到当前进程的内核栈，在当前进程的内核栈中就能找到tmp，而tmp指向下一个进程的PCB。下一个进程的PCB再指向下一个进程的内核栈，从当前进程的内核栈找到tmp。temp指向下下一个进程的PCB。这样就形成了一个阻塞队列。

然后就是如何唤醒队列。下面的方法将阻塞态中的所有进程都唤醒为就绪态，然后由schedule()来调度优先级最高的进程执行，优先级最高的进程执行后，会见b_ lock置为1，然后通过while(bh->b_lock)将其他进程重新置为阻塞态。具体工作原理如下：

![](https://i.imgur.com/KRNomSR.png)


### 死锁处理

多进程产生的问题：死锁。多个进程内存中同时出发、交替执行，如果控制不好，就会出现互相死锁的情况。


看一下生产者-消费者的信号量解法，来发现死锁问题：

![](https://i.imgur.com/oKEJoRj.png)

如果先申请mutex，再申请empty。这样会导致死锁。

假设当前缓冲区满了，则empty=0，并且设mutex=1。P(mutex)将mutex从1置为0，然后P(empty)将empty从0置为-1，生产者进程置为阻塞态。切换到消费者进程，P(mutex)将0置为-1，同样消费者进程为阻塞态。这样生产者进程和消费者进程都变成了阻塞态，无法继续执行。


生产者的P(empty)要执行，必须依赖于V(empty)将empty置为正数，而V(empty)的执行依赖于消费者进程中的P(mutex)执行，而P(mutex)得执行依赖于生产者进程中的V(mutex)将mutex置为1，而V(mutex)得执行以来于生产者进程中的P(empty)，这样就形成了一个环。即形成了死锁。

![](https://i.imgur.com/5KGy1jo.png)

将这种多个进程由于相互等待对方持有的资源而造成的谁都无法执行的情况叫死锁。死锁导致资源进程死锁越来越多，浪费的资源越来越多，CPU没有进程执行，CPU利用率极低，到最后计算机停止工作。上述生产者-消费者进程一旦死锁，那么mutex就一直占用无法释放，下一个使用mutex的进程使用mutex的时候，也会导致死锁。这样一直继续下去。

死锁的成因：

![](https://i.imgur.com/TVnAoXP.png)


死锁的4个必要条件：

![](https://i.imgur.com/vorwQv7.png)



#### 死锁处理方法

跟火灾做类比

- 死锁预防：破坏死锁出现的必要条件，就像预防火灾，禁止吸烟
- 死锁避免：检测每个资源请求，如果造成死锁就拒绝，就像检测到煤气超标，自动切换电源；
- 死锁检查和恢复：检测到死锁出现时，让一些进程回滚，让出资源，就像发现火灾时，立刻拿起灭火器
- 死锁忽略：就好像没有出现死锁一样，就像太阳上可以对火灾全然不顾


死锁预防：

-  在进程执行前，一次性申请所有需要的资源，不会占有资源再去申请其他资源
	- 缺点1： 需要预知未来，编程困难；
	- 缺点2：需要资源分配很长时间后才使用，资源利用率低

- 对资源类型进行排序，自然也申请必须按序进行，不会出现环路等待
	- 缺点： 仍然造成资源浪费


死锁避免： 判断此次请求是否会引起死锁？

![](https://i.imgur.com/PGaDVcm.png)

序列A时安全的。 Alloaction表示占用的资源，Need表示进程执行需要的资源，Avaiable表示当前可用的资源。

可以利用算法来至少安全序列。

![](https://i.imgur.com/5uFdvFc.png)

银行家算法代价比较大。m表示资源，n表示进程数量。系统中资源和进程数量都是巨大的。

在实际中，通过向假装分配，分配利用银行家算法判断是否会造成死锁，如果造成死锁则对申请拒绝。

![](https://i.imgur.com/DHXgvXJ.png)



死锁检查和恢复：发现问题再处理

![](https://i.imgur.com/GjRwR7L.png)


## 内存管理

### 内存使用与分段

#### 内存如何使用

将程序放入内存中，PC指向开始地址，CPU从内存中取值执行。

如何让程序放入内存中？程序编译完成，放在磁盘中。从磁盘读一下，将01代码放入内存中。但是放入内存中的什么位置呢？

![](https://i.imgur.com/KF2ky5G.png)


上图中是一个main()函数，main函数应该放到地址40处。所以从磁盘读取的代码应该放入内存中地址为40的地方。

这样内存就可以使用了，但是编写的程序的要求main()必须放到内存中地址40处。问题是，内存中的地址可能被占用，哪怎么办呢？

应该是从内存找一块空闲的地址。一个程序放到内存中一个空间的地方，程序还是无法执行。比如上面的IP指向1000，而call 40不是程序的地址，程序的地址是1040。

![](https://i.imgur.com/IrlnuML.png)

40是逻辑地址，要使用内存必须修改成物理地址。即将40修改成1040，这种修改叫做重定位。这样才能正确执行程序。

在什么时候进行重定位呢？

一种在编译时，编译时给地址加上基地址；缺点是在编译时需要知道内存中哪块地址是空闲的，在实际中，系统无法知道。另一种是在载入时，找到内存中空闲的地址，载入的时候发现1000空闲，将程序中的地址统统加上1000；这样比较灵活。一旦载入后，程序就不能移动。

实际中，程序载入后还需要移动。

![](https://i.imgur.com/wyBmhPX.png)

载入后重定位还是无法满足要求。应该是__运行时重定位__，也叫做地址翻译。每次运行时给程序中所有地址加上基地址（base）,base放在PCB（描述进程的数据结构）中。

![](https://i.imgur.com/f56OB7M.png)

首先到内存中找一块空闲内存，得到基地址，将程序载入空闲内存中，然后将基地址写入进程的PCB中，最后，在执行程序的过程中，每取出一条指令的时候加上基地址进行重定位。


#### 引入分段

每一部分都是从零开始。变量集中的偏移300，是偏移变量段中300。

![](https://i.imgur.com/3xTJJ2M.png)

采用分治，用户可以独立考虑每个部分。因为每个部分都有各自的特点。主程序只读，变量集可写。如果两个放在一起处理，操作变量的时候，可能修改程序段，这样是不合适的，所以分开考虑是必要的。同时，有些函数库可以不载入，比如动态链接库；有些库需要载入。如果所有程序一起考虑，那么所有库都要载入。

分段放入内存中，还有一个好处就是，但某段的内存不足时，只要复制该段到一个更大的空闲内存中。如果不进行分段，首先将内存不足的段扩大，然后需要将整个程序复制到一个更大的空闲内存中，这样效率低。

![](https://i.imgur.com/2V6rimA.png)

其中DS=1表示段号为1，CS=0表示段号为1。

每个进程都有一套段表，叫做LDT，LDT放在进程的PCB中。操作系统的段表就是GDT表。


![](https://i.imgur.com/OPVTGYp.png)


### 内存分区与分页

如何在内存中找到一块空闲的内存块。说到内存块，就有内存分区的概念。

内存管理三个步骤： 程序分段（编译） ->  在内存中划分空闲区域 ->  通过磁盘读写载入到内存，建立LDT表

如何在内存找出一段空闲的区域？

内存是怎么分割的？

#### 内存分区

__固定分区和可变分区__

给你一个面包，一堆孩子来吃，怎么办？

- 等分，操作系统初始化时将内存等分成k个分区
- 但孩子有大有小，段也有大有小，需求不一定。

实际中采用可变分区，根据段请求，在空闲分区中割一段分配给该段。

通过一些数据结构来管理可变分区。

![](https://i.imgur.com/rQPb3G5.png)

处理一个段请求如下：

![](https://i.imgur.com/c8ra0ij.png)

空闲分区表需要改变，已分配分区表添加一行。空闲分区表中的始址变为350K，长度标为150K。

进程退出，则使用的内存都会释放。这样空闲内存将不再是一块，而是一块一块的。如下：

![](https://i.imgur.com/QSxlMaV.png)

此时，如果进程再次进来进行申请，选择哪个空闲块分配给进程呢？这就需要使用算法来进行分配：

![](https://i.imgur.com/HBEjDnv.png)

- 最佳适配： 选择最接近请求空闲内存大小的空闲内存，这样会导致生成一堆细小的空闲内存 o(n)
- 最差适配： 选择空闲内存中最大的空闲块分配给请求， 得到一些比较均匀的空闲内存  o(n)
- 首先适配： 速度块 o(1)

![](https://i.imgur.com/N52JwUL.png)

答案是 B  最佳适配会产生一堆细小的空闲内存块，而题目中刚好有这样的q;qq

在实际系统中，并不是用内存分区来进行物理内存的分割。而是通过分页来进行物理内存进行分割。内存分区是对虚拟内存的处理，后面讲解。


#### 内存分页


引入分页：解决内存分区导致的内存效率问题

![](https://i.imgur.com/5ZcyR6i.png)

存在内存碎片问题，内存紧缩方法花费时间太长，不可行。

另一个方法是：将160打碎，分成100K和40K，这样就可以请求空闲内存了，这就是分页。


![](https://i.imgur.com/a1YnwoE.png)

此时不再需要内存紧缩，因为最多浪费一页内存，而一页内存非常小，所以物理内存浪费少。

程序分段，物理内存分页。

![](https://i.imgur.com/agh6lA3.png)

对于一个逻辑地址，首先除以页面尺寸大小，此处为4K，表示将逻辑地址右移12位，得到2，即表示页号为2，找到内存中对应的页框号为3；然后将地址除以页面尺寸大小得到的余数（240）加上页框号乘以页面尺寸（3左移动12位）就可以得到物理地址（0x3240）。


### 多级页表与快表

分页机制还存在问题。就需要多级页表与快表进行解决。意思是，分页、多级页表和快表结合在一起就能形成一套高效的完整的机制。

分页的问题：

![](https://i.imgur.com/Vby8g3z.png)

页小（比如4K）页表就大了。页大了就会浪费内存。

![](https://i.imgur.com/8i65Yi8.png)

不使用的逻辑页号从页表中去掉。只存放用到的页。

![](https://i.imgur.com/NVNlaq2.png)

只存储用到的页，这样会导致表不连续。就需要对表进行查找，而查找非常耗时，是不可行的。比如，4G的内存，对半查找需要20次，这样导致一次内存访问附带了20的内存访问查找表，而CPU的执行非常快，对于CPU访问内存本来就慢，还一次内存访问，还附带了20次的内存访问查找，这样速度就更慢。

而如果是连续的，就不需要查找，直接将表的起始地址加上偏移就找到了对应的页号。这样只要查一次，速度就快。缺点就算没有使用的页号也要存储在页表中，这样才能连续，造成页表的表项特别多。页表很大，造成浪费。

需要找到一种方法使得页表小，而且连续。可以类比书的章目录和节目录来思考。

![](https://i.imgur.com/0MtDXlm.png)

多级页表仍然是连续的，不需要进行比较查找。内存中存储的表项大大变小。

多级页表的问题：

空间利用率高，但是时间消耗大。

![](https://i.imgur.com/l8xa3c6.png)

利用快表解决时间问题。首先在TLB中查找，没有查找到再去查找多级页表。最近经常使用的页表项放入快表TLB中。

TLB发挥作用的原因：

![](https://i.imgur.com/EHPoNMZ.png)

### 段页结合的实际内存管理

段页结合：程序员希望用段，物理内存希望用页

![](https://i.imgur.com/oHZmuHZ.png)

在虚拟内存中割出一个区域分配给应用程序。在虚拟内存中的段分成一页一页，然后跟物理内存关联在一起。

![](https://i.imgur.com/vYKW3lM.png)

__逻辑地址（段号+偏移）__根据段表找到基址，基址加上段内偏移产生出一个__虚拟地址__ 。根据虚拟地址算出页号和偏移，再根据分页机制，找到页号对应的页框号，页框号乘以页面大小加上偏移得到__物理地址__。

#### 一个实际的段、页式内存管理

![](https://i.imgur.com/aMCd36L.png)

程序载入内存：

![](https://i.imgur.com/lXaCg6T.png)


整个过程分为3步：第一步：在虚拟内存分割一快空闲区域；第二步：将程序段假装放入虚拟内存；第三步：在物理内存中查找空闲页；第四步：建立页表，实现虚拟内存到物理内存。第五步：重定位使用内存。

![](https://i.imgur.com/OY9j69l.png)

P是PCB。

![](https://i.imgur.com/CrKIjee.png)

![](https://i.imgur.com/YqskCxq.png)

![](https://i.imgur.com/3cTuRSP.png)


### 内存换入——请求调页

实现分段和分页，需要使用虚拟内存，而使用虚拟内存必须有换入换出。

![](https://i.imgur.com/IeBuQwQ.png)

请求的时候才换入并建立映射。

![](https://i.imgur.com/Kq4C6lO.png)

一旦发现当前的虚拟在页表中没必要映射，即缺页，就会发起中断，然后页错误处理程序去磁盘读取对应页放入空闲物理内存页，然后虚拟内存建立映射。这样，就可以正常执行了。


一个实际系统的请求调页：

![](https://i.imgur.com/HW6N2jO.png)

### 内存换出

如果一直换入，则物理内存总会满。所以，需要将物理内存页换出到磁盘中。
 
![](https://i.imgur.com/pCx9RIP.png)

接下来，主要是分析算法换出哪一页？

![](https://i.imgur.com/mh6GNyl.png)

缺页次数较少时，采用FIFO。

![](https://i.imgur.com/vmmDcgk.png)

LRU利用程序的局部性特点。

LRU的准确实现的两种方法：

![](https://i.imgur.com/aV50ypU.png)

LRU的准确实现，代价太大。LRU的近似实现：

二次机会算法SCR也称Clock算法。

![](https://i.imgur.com/qvBqN6P.png)

R=0表示最近没被使用。R=1表示最近被使用了。

如果缺页很少，则所有的R都会等于1。如果再出现缺页，会将所有的R置为0，并将第一个置为1的页换出。再次缺页，就换出第二个置为1的页，依次类推，这就退化成了FIFO。原因是，R转的太慢，没法反映最近的概念。

![](https://i.imgur.com/Ftjxebh.png)

扫描指针将R从1置为0。

置换策略解决了，还需要知道给一个进程分配多少个页框。

![](https://i.imgur.com/FnsW50e.png)

多道升序程度表示进程数量。

如果一个进程需要4页，而只分配3页，就会出现颠簸。解决方法经常求出局部需要的页数量，通过求工作集的方法来实现。

__总结__

![](https://i.imgur.com/Iwt61E1.png)


## IO系统

![](https://i.imgur.com/ZDTwMZS.png)

显示器、键盘、磁盘（文件、文件系统）

![](https://i.imgur.com/vPnW9zP.png)

给相应的外设的寄存器或控制器发送指令，然后通过文件形成文件视图；最后向CPU发送中断。

使用外设，向设备控制器的寄存器写内容就可以了。但是需要查寄存器地址、内容的格式和语义，操作系统要给用户提供一个简单视图——文件视图，这样方便。

一段操作外设的程序：

![](https://i.imgur.com/vB61SHu.png)

![](https://i.imgur.com/tjSUGLC.png)


### 显示器

![](https://i.imgur.com/IkDDs8s.png)

在显示器打印内容的整个过程：

![](https://i.imgur.com/VOIMQZi.png)

### 键盘

按下键盘，就发起了中断。

![](https://i.imgur.com/eUO46P6.png)

键盘和显示器结合在一起：

![](https://i.imgur.com/Nepr9Ak.png)


### 磁盘

#### 生磁盘的使用

CPU向IDE控制器写一些指令，读写磁盘，读写完成向CPU发起中断。

![](https://i.imgur.com/XkR8zl6.png)

磁盘中有磁，磁头里面有电，磁和电相互转换，最后磁信号变成了电信号，从而读出了磁盘。读写磁盘的单位是扇区，即一个扇区一个扇区读写。

![](https://i.imgur.com/6lxuIOF.png)

磁盘如何读写一个字节：首先，磁头移动到指定的磁道上，磁盘开始旋转，转到对应的扇区后，再一转就磁生电，磁信号变成电信号，读入内存缓存区。然后再内存中修改一个字节，最后将电信号转为磁信号，写入磁盘。

三个步骤： 移动磁头到相应磁道上->旋转磁盘到对应的扇区->与内存进行读写

![](https://i.imgur.com/g4jpCfg.png)

最直接使用磁盘：只要往磁盘控制中写柱面、磁头、扇区、缓冲区位置。

- 柱面：确定磁道
- 磁头：确定盘面
- 扇区：柱面和磁头确定一个圆，通过扇区确定圆中的哪个部分。

有了这三个量就知道在磁盘什么位置读写数据。然后将磁盘中的数据读入缓冲区或从缓冲区读取数据写入磁盘。

![](https://i.imgur.com/aVCPlV1.png)

上面方法对于用户使用而言，太困难，需要知道的量太多。于是考虑通过一个量来定位磁盘中的数据，中间的计算柱面、磁头和扇区交给磁盘驱动去计算。这个量就是盘块号。

__第一层抽象__

![](https://i.imgur.com/EgzX6Dv.png)

可将，寻道的时间是最长的。所以，相邻的盘块号存在一个磁道上，可以节省大量时间。

![](https://i.imgur.com/Gh55lEj.png)

注意： block = C×(Heads×Sectors)+H×Sectors+S -> S=block%Sectors。

每次访问磁盘，希望多读取内容，因此每次磁盘访问都要花费比较多的时间，特别是寻道和旋转实现。而磁盘的最小读取单位是扇区，引进盘块，可以增加每次磁盘读取的内容，这样就能提高磁盘读取的时间效率。但是这样会导致磁盘空间利用率会降低，因为如果一个盘块存储了内容，没有填满，但是不能再填充内容。通过降低磁盘利用率来提供时间效率。 

一个盘块包含多个连续扇区。Linux的盘块是2个扇区（sector）。

__第二层抽象__

多个进程请求访问磁盘时，就需要请求队列。每做完一件事，发生中断，磁盘驱动从请求队列中取出。

![](https://i.imgur.com/y4iP3Ob.png)

根据盘块号来访问磁盘，是生磁盘。如果通过文件来访问磁盘，就变成了熟磁盘。

先来先服务FCFS：

![](https://i.imgur.com/i4oqgF8.png)

最短寻道优先SSTF

![](https://i.imgur.com/whVaCBG.png)

电梯算法SCAN:

![](https://i.imgur.com/2IKRGuB.png)

电梯算法C-SCAN

![](https://i.imgur.com/swQqIv9.png)

生磁盘使用总结：

![](https://i.imgur.com/yKFqBlI.png)

第一步中的扇区号，是盘块号中多个连续扇区的起始扇区号。


#### 从生磁盘到文件

核心：如何从文件到盘块号？反过来怎么从盘块号抽象出文件？

引入文件，对磁盘使用的第三层抽象：

![](https://i.imgur.com/yner1sP.png)

用户眼中的文件是字符序列。磁盘上的文件是由一堆盘块连接在一起组成的。

文件核心在于：建立字符流到盘块集合的映射关系。

映射的作用：

![](https://i.imgur.com/dH440mJ.png)

- 连续结构来实现文件：

在test.c中，假设0-99字节的文件存放在第6个盘块，100-199存放在第7个盘块上，200-299存放在第8个盘块上。这样，根据200-212就可以算出在哪个盘块上，即第8号盘块上。计算公式： 200/100+6=8，所以test.c的FCB表格中需要存放起始盘块号（这里是6）和连续的块数（这里是3）。

这样读写磁盘就变成了读写文件中的第几个字符。 文件中的字符->盘块号->扇区、磁头、柱面->磁盘中的文件

在这种情况下，如果testc文件增加到14块时，就需要覆盖第14块，于是考虑将文件移动到更大的连续空间，但是这样非常耗时。所以这种结构，对于__文件动态增长不适合__。这种结构类似于数组。对于词典文件基本不变适合采用这种方式存储。

对于动态文件考虑采用链式结构来存储。

- 链式结构实现文件

类似于链表数据结构。这时文件的FCB表格只需要存储起始块，而不要存储连续的块数量。

![](https://i.imgur.com/mmcTeZC.png)

适用于动态增长文件。但是读写速度慢。

- 索引结构实现文件

需要一个盘块来做索引。这样只要做索引的盘块存储到文件的FCB表格中。

![](https://i.imgur.com/tpgTHAB.png)

适用于动态增长文件，读写速度块。

- 多级索引结构实现文件

![](https://i.imgur.com/jFvp7Ks.png)

小文件直接对应盘块，直接读写。中间大小文件采用一级索引。大文件采用二级索引。

![](https://i.imgur.com/UCVxyI0.png)

答案： A

#### 文件使用磁盘的实现

![](https://i.imgur.com/LWZW5kv.png)


![](https://i.imgur.com/XMSMKkf.png)

根据file，count确定200-212，然后根据inode表格中的索引表确定盘块号。其中file是一个指针，指向文件的开始，count表示读取文件的字符数量。

利用盘块号、buf形成请求，利用电梯算法放入请求队列。

file_write实现：

![](https://i.imgur.com/QSUqEDt.png)

create_block实现：

![](https://i.imgur.com/157qpJi.png)

首先根据一个盘块中存储的字符数量，算出需要读的字符位于第几个盘块，然后在索引表中找到对应盘块。

Linux中，一个盘块包括2个扇区，占1K=0124个字节。一个盘块号占2个字节，所以一个索引表可以索引到512个盘块。

inode除了作为一个映射表从文件对应到盘块号为，还是文件抽象。文件还包括设备文件，设备文件应包括主设备号、次设备号等信息，而不需要映射表。

![](https://i.imgur.com/KKeL7sj.png)

![](https://i.imgur.com/gzD6Tqy.png)

文件名-> inode -> 盘块号 -> CHS -> 磁盘控制器 -> 磁生电电生磁读写文件

#### 目录与文件系统

![](https://i.imgur.com/ZZNsX5K.png)

文件系统是一堆文件到盘块集合。

![](https://i.imgur.com/nmGOKOP.png)

文件系统按照树结构存储多文件。文件系统将磁盘上所有盘块抽象成一个目录树结构。

前面是研究一个文件怎么映射到磁盘中的盘块。而这里研究一堆文件对应到磁盘中的盘块。


所有文件放在一个层：用户查找文件非常困难

每个用户放在一个集合： 还是比较复制

![](https://i.imgur.com/EDHfeyg.png)


引入目录树： （分治的思想）

![](https://i.imgur.com/A7Kn1Kk.png)

路径名：

![](https://i.imgur.com/gZx4Vep.png)

根据FCB就能找到盘块号，这样就接上了单文件情形。

第四层抽象的核心就是：路径名映射到FCB。

磁盘块中存放什么信息来实现目录？

每个目录存放目录下所有文件名和对应的FCB的”地址”（编号）。如果读取整个FCB表格，而不是编号，这样读写磁盘的时间将大大增长。

![](https://i.imgur.com/Hp5HV96.png)

磁盘中存放的信息：

![](https://i.imgur.com/xVLJHaE.png)

盘块位图能够表示空闲的盘块，inode位图表示可以存放多少个文件，哪些文件被占用。超级块记录两个位图有多大等信息。

总结：

![](https://i.imgur.com/LXAFBsq.png)

#### 目录解析代码实现


![](https://i.imgur.com/SwPyIUl.png)

## 操作系统全图

多进程视图：CPU取值执行，多个程序交替执行，让CPU充分忙碌。

内存：分段、分页，段页合作，换入换出

文件视图：磁盘读写、IO设备




